{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e183ea",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    " 1. [Imports](#Imports)\n",
    " 2. [Reading Data](#Reading-Data)\n",
    " 3. [Preprocessing](#Preprocessing)\n",
    " 4. [Set up our data for modeling](#Set-up-our-data-for-modeling)\n",
    "     1. [Final Model](#Final-Model)\n",
    " 5. [Model Analysis](#Model-Analysis)\n",
    "     1. [Compiled Scores](#Compiled-Scores)\n",
    "     1. [Confusion Matrix](#Confusion-Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc70871",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afbfe294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493f3455",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8bff270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>type</th>\n",
       "      <th>target</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usgs reports a m earthquake  km ese of beatty ...</td>\n",
       "      <td>{'longitude': -116.2717, 'latitude': 36.7641}</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0</td>\n",
       "      <td>36.764100</td>\n",
       "      <td>-116.271700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usgs reports a m1 earthquake  km wnw of smiths...</td>\n",
       "      <td>{'longitude': -116.1626667, 'latitude': 44.3195}</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0</td>\n",
       "      <td>44.319500</td>\n",
       "      <td>-116.162667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usgs reports a m earthquake  km nw of indian s...</td>\n",
       "      <td>{'longitude': -116.0749, 'latitude': 36.7963}</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0</td>\n",
       "      <td>36.796300</td>\n",
       "      <td>-116.074900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usgs reports a m11 earthquake  km ssw of markl...</td>\n",
       "      <td>{'longitude': -119.8126, 'latitude': 38.6329}</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0</td>\n",
       "      <td>38.632900</td>\n",
       "      <td>-119.812600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>moffshore valparaiso chile depth km may 9  1 u...</td>\n",
       "      <td>{'longitude': -71.84, 'latitude': -32.51}</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0</td>\n",
       "      <td>-32.510000</td>\n",
       "      <td>-71.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>usgs reports a m earthquake  km wsw of cold sp...</td>\n",
       "      <td>{'longitude': -120.072, 'latitude': 39.6527}</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0</td>\n",
       "      <td>39.652700</td>\n",
       "      <td>-120.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>usgs reports a m19 earthquake  km wnw of stanl...</td>\n",
       "      <td>{'longitude': -115.1751667, 'latitude': 44.2765}</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0</td>\n",
       "      <td>44.276500</td>\n",
       "      <td>-115.175167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>usgs reports a m11 earthquake  km nnw of gabbs...</td>\n",
       "      <td>{'longitude': -118.1133, 'latitude': 39.3157}</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0</td>\n",
       "      <td>39.315700</td>\n",
       "      <td>-118.113300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>i wanna move out of the #usa but if shit goes ...</td>\n",
       "      <td>{'longitude': -87.940033, 'latitude': 41.644102}</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>1</td>\n",
       "      <td>41.644102</td>\n",
       "      <td>-87.940033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>usgs reports a m earthquake  km nw of stanley ...</td>\n",
       "      <td>{'longitude': -115.2083333, 'latitude': 44.3585}</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0</td>\n",
       "      <td>44.358500</td>\n",
       "      <td>-115.208333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  usgs reports a m earthquake  km ese of beatty ...   \n",
       "1  usgs reports a m1 earthquake  km wnw of smiths...   \n",
       "2  usgs reports a m earthquake  km nw of indian s...   \n",
       "3  usgs reports a m11 earthquake  km ssw of markl...   \n",
       "4  moffshore valparaiso chile depth km may 9  1 u...   \n",
       "5  usgs reports a m earthquake  km wsw of cold sp...   \n",
       "6  usgs reports a m19 earthquake  km wnw of stanl...   \n",
       "7  usgs reports a m11 earthquake  km nnw of gabbs...   \n",
       "8  i wanna move out of the #usa but if shit goes ...   \n",
       "9  usgs reports a m earthquake  km nw of stanley ...   \n",
       "\n",
       "                                        coordinates        type  target  \\\n",
       "0     {'longitude': -116.2717, 'latitude': 36.7641}  earthquake       0   \n",
       "1  {'longitude': -116.1626667, 'latitude': 44.3195}  earthquake       0   \n",
       "2     {'longitude': -116.0749, 'latitude': 36.7963}  earthquake       0   \n",
       "3     {'longitude': -119.8126, 'latitude': 38.6329}  earthquake       0   \n",
       "4         {'longitude': -71.84, 'latitude': -32.51}  earthquake       0   \n",
       "5      {'longitude': -120.072, 'latitude': 39.6527}  earthquake       0   \n",
       "6  {'longitude': -115.1751667, 'latitude': 44.2765}  earthquake       0   \n",
       "7     {'longitude': -118.1133, 'latitude': 39.3157}  earthquake       0   \n",
       "8  {'longitude': -87.940033, 'latitude': 41.644102}  earthquake       1   \n",
       "9  {'longitude': -115.2083333, 'latitude': 44.3585}  earthquake       0   \n",
       "\n",
       "    latitude   longitude  \n",
       "0  36.764100 -116.271700  \n",
       "1  44.319500 -116.162667  \n",
       "2  36.796300 -116.074900  \n",
       "3  38.632900 -119.812600  \n",
       "4 -32.510000  -71.840000  \n",
       "5  39.652700 -120.072000  \n",
       "6  44.276500 -115.175167  \n",
       "7  39.315700 -118.113300  \n",
       "8  41.644102  -87.940033  \n",
       "9  44.358500 -115.208333  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('clean_df.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f837d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content        0\n",
       "coordinates    0\n",
       "type           0\n",
       "target         0\n",
       "latitude       0\n",
       "longitude      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double checking for nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b01a1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_words(text):\n",
    "    words = text.split()\n",
    "    lemma_words =''\n",
    "    for word in words:\n",
    "        lemma_words += (lemmatizer.lemmatize(word) + ' ')\n",
    "    return lemma_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596ee402",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].apply(lemmatize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b928fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most Frequently used words\n",
    "\n",
    "count_vect = CountVectorizer(analyzer=\"word\", tokenizer = None, preprocessor = None, stop_words = \"english\", ngram_range=(1,1))\n",
    "\n",
    "# Netflix CountVectorizer \n",
    "\n",
    "df_twitter_words_danger = df[df['target'] == 1]['content']\n",
    "\n",
    "# fit_transform the vectorizer\n",
    "\n",
    "twitter_words_d = count_vect.fit_transform(df_twitter_words_danger)\n",
    "\n",
    "#Convert output to Numpy Array\n",
    "\n",
    "twitter_words_d = twitter_words_d.toarray()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "483d22e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11', '111amplified', '119', '11a11p', '11mph', '11th', '19', '1911', '199', '1999', '1999191', '19s', '19stoday', '1evanstewart', '1ft', '1hrs', '1k', '1kilometers', '1km', '1m', '1michael', '1mph', '1newsnow', '1pm', '1pmpm', '1st', '1tampabay', '1year', '91', '911', '99', '99fm', '9am', '9mbs', '9mph', '9pm', '9th', 'aa', 'aarn', 'aaronparnas', 'abandoning', 'abbeville', 'abbott', 'abbotts', 'abc', 'abc11wtvd', 'abc1news', 'abc1newssydweather', 'abcchicago', 'abel', 'abilene', 'ability', 'able', 'abomb', 'abomination', 'abortion', 'absolute', 'absolutely', 'abusive', 'academy', 'accept', 'acceptable', 'access', 'accident', 'accompanied', 'accomplish', 'according', 'account', 'accurate', 'acevandeuce', 'achucksnake', 'acme', 'acre', 'act', 'actahoops', 'action', 'actionvote', 'activate', 'activated', 'active', 'actively', 'activity', 'actual', 'actually', 'acuoutrunners', 'acyn', 'ad', 'adafriendly', 'adam', 'adamluciowx', 'adapting', 'add', 'added', 'addicted', 'adding', 'addison', 'addition', 'additional', 'address', 'addressed', 'addressing', 'adfriendly', 'adjacent', 'admiration', 'admire', 'adriennewavy', 'adult', 'advance', 'advanced', 'advection', 'advice', 'advised', 'advisory', 'advocate', 'af', 'affect', 'affected', 'afford', 'affordable', 'afraid', 'africa', 'afrique', 'aftermathcleanup', 'afternoon', 'afternoonevening', 'afton', 'againbasically', 'age', 'agency', 'agencyso', 'agenda', 'agent', 'aggie', 'agitated', 'ago', 'agomore', 'agree', 'agreed', 'agreement', 'agriculture', 'agtwitter', 'ah', 'ahead', 'ahhh', 'aht', 'aid', 'aim', 'ainsworth', 'aint', 'air', 'airport', 'airy', 'aisle', 'ak1', 'al', 'alabama', 'alan', 'alarm', 'albemarle', 'albertus', 'album', 'alcoholic', 'alert', 'alertdurham', 'alerted', 'alexander', 'alexandria', 'alexgardner', 'alexisxelliott', 'alexmurphy', 'alice', 'allegan', 'alley', 'alli', 'alll', 'allow', 'allowed', 'allowing', 'alls', 'allthe', 'alltime', 'alma', 'alongside', 'alonzo', 'alpine', 'altus', 'alwx', 'amaliada', 'amandawfxr', 'amarillo', 'amateur', 'amazing', 'amazon', 'amberheards', 'ambulance', 'america', 'americafirst', 'americaisbroken', 'american', 'american19', 'amherst', 'amhq', 'ammocarclub', 'amobile', 'amp', 'amp1st', 'ampamp', 'ampasked', 'amy', 'amyriscool', 'anchor', 'anchorage', 'ancommiey', 'anderson', 'andmy', 'andover', 'andreas', 'andrei', 'andrew', 'andrewnbc1', 'anemic', 'angelo', 'angelobav', 'anger', 'angry', 'animazement', 'ann', 'annemariefassl1', 'anniedelbel', 'announcement', 'annoying', 'annual', 'annually', 'anomalous', 'anson', 'answer', 'answering', 'anthony', 'antiblack', 'anxiety', 'anxious', 'anymore', 'anyways', 'aodespair', 'ap', 'apart', 'apartment', 'apex', 'apologize', 'apology', 'app', 'apparatus', 'apparently', 'appear', 'appearing', 'apple', 'applemusic', 'applied', 'apply', 'appomattox', 'appreciate', 'approached', 'approaching', 'approximately', 'april', 'aquasco', 'aquifer', 'ar', 'ar1', 'ar1s', 'ararat', 'arcade', 'area', 'areaunderstand', 'arent', 'argument', 'arizona', 'arjunm11', 'ark', 'arkansas', 'arlington', 'arm', 'armed', 'armor', 'armored', 'aroostook', 'aroundeveryone', 'arrested', 'arrington', 'arsenic', 'arstormteam', 'art', 'artchallenge', 'artist', 'arwx', 'asanderford', 'asf', 'ash', 'ashamed', 'asheboro', 'asian', 'ask', 'asked', 'asking', 'asleep', 'ass', 'assam', 'assault', 'asshole', 'assisting', 'associated', 'assume', 'assumed', 'asthmatic', 'astonishing', 'astral', 'astronomy', 'asylum', 'atheist', 'atlanta', 'atlantic', 'atmosphere', 'atom', 'atrupar', 'attacking', 'attempt', 'attempted', 'attend', 'attended', 'attendee', 'attention', 'attitude', 'au', 'auburn', 'austin', 'austinfc', 'authority', 'autism', 'automatic', 'autotweet', 'available', 'avalanche', 'ave', 'avent', 'avenue', 'average', 'aviso', 'avoid', 'award', 'aware', 'awareness', 'away', 'awe', 'awesome', 'awful', 'awhitehorse', 'aynor', 'ayo', 'azstormchase', 'baby', 'baccalaureate', 'background', 'backinblackwx', 'backyard', 'bad', 'badbux', 'baddogs', 'badge', 'bae', 'bag', 'bail', 'bainbridge', 'bait', 'baiting', 'baker', 'balanced', 'baldwin', 'balk', 'ball', 'ballparkbryan', 'baltimore', 'bam', 'bambrooklyn', 'banana', 'bancroft', 'band', 'bandaid', 'bandainamcoplay', 'bang', 'bank', 'banker', 'banking', 'bannerite', 'banning', 'bar', 'bare', 'barely', 'barney', 'barriomike', 'barstoolnate', 'bartholomew', 'bartley', 'base', 'baseball', 'baseballtiffin', 'based', 'basement', 'basically', 'basin', 'basis', 'bat', 'bathroom', 'battle', 'bay', 'bayou', 'bbq', 'bc', 'bcus', 'bcz', 'beach', 'beachy', 'bean', 'bear', 'beat', 'beautiful', 'beauty', 'beaver', 'beaverdale', 'beaverdam', 'beccafurnish', 'becker', 'beckyhammer', 'bedford', 'bedroom', 'beethoven', 'began', 'beganto', 'begin', 'beginning', 'behavior', 'bel', 'belief', 'believe', 'believing', 'bell', 'beloit', 'belts', 'belwood', 'ben', 'benedict', 'bengoldmantv', 'benifit', 'benjamin', 'benjamingoggin', 'benmaller', 'benopaonyx1', 'benshapiro', 'berea', 'bergen', 'bernard', 'berserkerbill', 'bessemer', 'best', 'bet', 'bethania', 'bethlehem', 'beto', 'betoorourke', 'better', 'betting', 'beverlyfolkers', 'bf', 'biannually', 'bible11there', 'biden', 'big', 'bigdee9999', 'bigger', 'biggest', 'biggestever', 'bigxii', 'billflood', 'billion', 'billionaire', 'binghamton', 'binghamtown', 'bio', 'bioapplemusic', 'bipartisan', 'birth', 'birthday', 'bish', 'bison', 'bit', 'bitch', 'bitter', 'bivinsethanstringer', 'black', 'blackbeltx1', 'blacklivesmatter', 'blackmont', 'blackout', 'blackrock', 'blacksburg', 'blacktwitter', 'blame', 'blaming', 'blanco', 'blaring', 'blas', 'bleacherreport', 'blessed', 'blessing', 'blind', 'block', 'blocking', 'blonde', 'blood', 'bloody', 'bloomfield', 'blooming', 'bloomingdale', 'blooper', 'blown', 'blue', 'bluekandywx', 'bluevoices', 'bluff', 'blvd', 'bmalmet', 'bmore', 'board', 'boat', 'boatsmy', 'bobbistorm', 'bobbyr11', 'bobl11', 'body', 'boiling', 'bolt', 'bomb', 'bombing', 'bombwhich', 'bonesio', 'bonus', 'bonusstagepub', 'book', 'bookend', 'bookended', 'booking', 'boone', 'boonville', 'border', 'borderhonestly', 'boring', 'born', 'boston', 'bot', 'bothered', 'bottle', 'bottlerock', 'bound', 'bout', 'bower', 'bowing', 'bowling', 'box', 'boxer', 'boy', 'boykin', 'bpopetv', 'bradarnoldwx', 'brain', 'branch', 'brand', 'brazil', 'brazilian', 'break', 'breaking', 'breakingnewsburke', 'breakwill', 'breannastewart', 'brendannyhan', 'brendonme', 'brettthackabc', 'brian', 'brianemfinger', 'briar', 'bridge', 'brief', 'briefly', 'brindamour', 'bring', 'bringing', 'brings', 'brink', 'british', 'brittanibitch', 'brittanylbranch', 'bro', 'broad', 'broadcast', 'brody', 'broke', 'broken', 'brokenburg', 'broker', 'brook', 'brooklyn', 'brookside', 'brother', 'brown', 'brownwood', 'bruce', 'brucecartier', 'bruh', 'bruin', 'brunominswater', 'brutal', 'bryanfenley', 'bryantown', 'brze', 'bsuchaseclass', 'btstaehyungthv', 'btw', 'bubble', 'buck', 'bucket', 'buffalomassacre', 'bugged', 'build', 'building', 'buildingwalker', 'built', 'bulletslife', 'bullied', 'bullshit', 'bullsht', 'bulwarkonline', 'bumpkin', 'bunch', 'bunchofjerks', 'bureaucracy', 'buren', 'burg', 'buried', 'burke', 'burlington', 'burn', 'burnie', 'burning', 'burst', 'bushesshrubbery', 'bushi', 'business', 'businesstips', 'busy', 'butt', 'butterfly', 'buy', 'bwg', 'bymikebaker', 'ca', 'cabarrus', 'cabin', 'cable', 'cadmium', 'cake', 'caldwell', 'calhoun', 'california', 'callands', 'called', 'calling', 'callmejc', 'calm', 'calmed', 'cam', 'cambria', 'camden', 'came', 'camelotgolf', 'camera', 'camp', 'campaign', 'campus', 'camvenablekake', 'canada', 'canadian', 'cancel', 'canceled', 'cancellation', 'cancelled', 'cancun', 'candicebergenmp', 'candiceking', 'candidate', 'canonusa', 'canton', 'cantoreif', 'cantplanforeverything', 'capable', 'capacity', 'cape', 'capitalweather', 'capitol', 'captain', 'captfan', 'captured', 'caput', 'car', 'card', 'cardiomyopathy', 'care', 'cared', 'career', 'cargo', 'carlheastie', 'carlsbad', 'carlson', 'carnival', 'carolina', 'carolinawxgroup', 'caroline', 'carolinian', 'carpentersville', 'carport', 'carrboro', 'carroll', 'carry', 'cartersville', 'carthage', 'cary', 'casblood1', 'cascabelli', 'case', 'cash', 'cast', 'castle', 'castro', 'casualtiesthe', 'cat', 'catastrophic', 'catawba', 'catch', 'catching', 'catcowx', 'catedailyboom', 'category', 'catholic', 'caught', 'cause', 'caused', 'causing', 'cbs', 'cbs19news', 'ccgevirtz', 'ccstormwatch', 'cdt', 'ceasefirefernando', 'cedar', 'celebration', 'cell', 'cent', 'center', 'centered', 'central', 'centurywhile', 'ceo', 'certain', 'certainly', 'cespedes', 'cfield', 'cfirefrost', 'chad', 'chaddingtonsc', 'chain', 'chair', 'challenge', 'challenged', 'chamber', 'chambliss', 'championship', 'championship1', 'chance', 'change', 'changed', 'changeits', 'channel', 'channelsthat', 'chantilly', 'chaos', 'chapel', 'chapman', 'chapmanks', 'charge', 'charger', 'charles', 'charlesville', 'charlotte', 'chase', 'chaser', 'chaserchapman', 'chasing', 'chat', 'chatbotshelped', 'chatmoss', 'chatsworth', 'cheating', 'check', 'checked', 'cheek', 'cheersdwayne', 'cheese', 'chef', 'chefjoseandres', 'chellgod', 'chelsealarsson', 'cherokee', 'cherryville', 'cherylscottwx', 'chesnee', 'chest', 'chester', 'chesterfield', 'chevy', 'chicago', 'chicagoland', 'chick', 'chickasha', 'chicken', 'child', 'childactive', 'childfire', 'childhood', 'children', 'childrenit', 'childrens', 'childrenshospitalnola', 'chile', 'chilean', 'chilliwack', 'chinese', 'chipley', 'chipnightingales', 'chix', 'choice', 'choked', 'choose', 'chorale', 'chose', 'chosen', 'chris', 'chrislhayes', 'chrismurphyct', 'christ', 'chron', 'chuck', 'chunk', 'church', 'chvrches', 'cia', 'cincinnati', 'cincinnatitodays', 'cincywx', 'cinoptic', 'cions', 'circle', 'circled', 'circulating', 'circulation', 'cite', 'citizen', 'city', 'citycounty', 'cityofdurhamnc', 'cityofmiami', 'cityofppines', 'cityofsunrise', 'cityoftoronto', 'cityofweston', 'citytornado', 'civil', 'civilian', 'cjwxguy', 'claiming', 'clamoring', 'claremont', 'clarendon', 'class', 'classic', 'classmate', 'classof', 'classroom', 'clay', 'clean', 'cleanenergy', 'cleaning', 'cleansing', 'cleanup', 'clear', 'clemson', 'cleveland', 'click', 'clifton', 'climate', 'climatecrisis', 'climatescience', 'climax', 'clitherall', 'clogged', 'close', 'closed', 'closely', 'closer', 'closest', 'closet', 'closing', 'closure', 'clothes', 'cloud', 'cloudgtrotating', 'cloudgtwall', 'cloudy', 'clt', 'cltwx', 'club', 'clutchsergal', 'cmbrlndvalleywx', 'cnn', 'cnnbrk', 'co19cox', 'coaching', 'coachjohnsonjr', 'coal', 'coast', 'coastal', 'coat', 'coatesville', 'cocaine', 'cocksucker', 'coconino', 'coconut', 'codered', 'coding', 'codyalcorn', 'coin', 'cold', 'collapse', 'collection', 'college', 'colleton', 'collinsville', 'colmar', 'color', 'colorado', 'colors', 'colour', 'columbia', 'combat', 'combined', 'combo', 'come', 'comerica', 'comfort', 'coming', 'commander', 'comment', 'commented', 'commercial', 'commissioned', 'commissioning', 'common', 'commoncause', 'commonplace', 'commonsense', 'commonsensegunlaws', 'communication', 'community', 'communityfoundation', 'company', 'compare', 'compared', 'comparison', 'complacent', 'complete', 'completely', 'complex', 'compliance', 'compromise', 'concept', 'concern', 'conclusion', 'concord', 'concurrent', 'condition', 'conesville', 'conference', 'confirmed', 'confronted', 'confusing', 'congratulation', 'congress', 'congressmanraja', 'connected', 'connection', 'connmagnet', 'connmunity', 'connor', 'conover', 'conrade', 'conscience', 'consequence', 'conservative', 'conservativesso', 'consider', 'considerationworries', 'considered', 'considering', 'conspiracy', 'constant', 'constantly', 'constituent', 'constitution', 'construction', 'consumersenergy', 'cont', 'contain', 'content', 'contextual', 'continue', 'continues', 'continuing', 'contract', 'contribute', 'contributing', 'control', 'controlled', 'convective', 'convention', 'conventionbut', 'conversation', 'converted', 'conway', 'cooksville', 'cool', 'cooland', 'cooling', 'coop', 'cooperate', 'cooperloyal', 'cop', 'coralville', 'core', 'corinne', 'corn', 'corner', 'cornyn', 'correct', 'correction', 'corrects', 'cortisol', 'corybivins', 'cosmic', 'cosmicrewind', 'cost', 'cotton', 'counter', 'counties', 'countless', 'country', 'county', 'county191', 'countyil', 'couple', 'course', 'coursetheyre', 'court', 'courthouse', 'courtney', 'cover', 'coverage', 'covered', 'covering', 'covid', 'covid19', 'covidbrain', 'cow', 'coward', 'cowx', 'cozumel', 'cpchq', 'cpr', 'cptnrawrpants', 'cr', 'crab', 'crack', 'cracking', 'crap', 'crash', 'crashing', 'crawfordsville', 'crazy', 'creamfan', 'create', 'created', 'creating', 'creation', 'credit', 'creek', 'creekmoore', 'creekrogerssale', 'crestwood', 'crevice', 'crime', 'crippling', 'crisis', 'crop', 'croplandyard', 'croplandyardbasement', 'crosby', 'cross', 'crossed', 'crossing', 'crow', 'crowd', 'crowdsource', 'cruise', 'cruiselife', 'cruz', 'crzytrainothght', 'ct', 'ctmagazine', 'ctr', 'cube', 'cubfan', 'cubsnhoks', 'culpeper', 'cult', 'cultivating', 'cultofgaryjay', 'culturaldeath', 'culture', 'culvert', 'cumberland', 'cumulus', 'cup', 'curb', 'current', 'currently', 'curtis', 'cusp', 'cut', 'cute', 'cutting', 'cuz', 'cvasquezforus', 'cvcams', 'cwarshaw', 'cyclonic', 'cyr', 'dabneys', 'dacholiday', 'dad', 'daileyweather', 'daily', 'dakota', 'dale', 'dallas', 'dam', 'damage', 'damage9mph', 'damaged', 'damaging', 'damians', 'damion', 'damm', 'damn', 'damnweve', 'damon', 'damoncpoole', 'dan', 'danamarante', 'danbury', 'dance', 'dancebut', 'dancing', 'dang', 'danger', 'dangerous', 'daniel', 'danielbonds', 'danieldefense', 'danielwhiteson', 'danrivolis', 'danville', 'danzarrow', 'darindeveauwx', 'dark', 'darkclouds', 'darkened', 'darling', 'darlington', 'dasher', 'dat', 'data', 'date', 'daughter', 'daveqzhang', 'davidjschmidt', 'davidshor', 'davis', 'day', 'daycare', 'dayton', 'dayz', 'dazzling', 'dbsb', 'dc', 'dcamychick', 'dctraffic', 'dcwx', 'ddfalpha', 'ddoggiesmommy', 'ddwchen', 'dead', 'deadly', 'deal', 'dealing', 'dealornodeal', 'dear', 'death', 'debarking', 'debate', 'debree', 'debris', 'debveglitter', 'decade', 'decent', 'decided', 'decides', 'decipher', 'decision', 'deck', 'declared', 'decline', 'declined', 'decorated', 'decoration', 'dedicated', 'deep', 'deeper', 'deer', 'defeated', 'defend', 'defense', 'deficiency', 'definitely', 'defoliation', 'degendojonft', 'dehumidifier', 'deja', 'dejoy', 'delaware', 'delay', 'delayed', 'delivered', 'delta', 'demand', 'democracy', 'demonstrate', 'demonstration', 'dems', 'denier', 'denning', 'dennison', 'denominator', 'dense', 'department', 'depend', 'depending', 'deposit', 'depression', 'dept', 'deptofdefense', 'deptrescue', 'depts', 'derecho', 'derekjstern', 'derekrude1', 'derive', 'descend', 'describedyou', 'describes', 'desensitized', 'desert', 'deserve', 'designed', 'desk', 'despair', 'despite', 'destination', 'destiny', 'destrehan', 'destroy', 'destroyed', 'destroying', 'destruction', 'detai', 'detector', 'detention', 'determine', 'determined', 'detroit', 'devastated', 'devastating', 'devastation', 'develop', 'developer', 'developing', 'developingsome', 'development', 'device', 'dewitt', 'dey', 'dgco', 'diamondhead', 'diaper', 'diapersunidentified', 'dick', 'dickinson', 'dictatorship', 'did', 'didnt', 'die', 'died', 'difference', 'different', 'difficult', 'dig', 'dike', 'dil', 'dingo', 'dinos', 'dinosaurhow', 'direct', 'direction', 'directly', 'dirt', 'dis', 'disabled', 'disappeared', 'disappoint', 'disaster', 'disasteri', 'disasterrecovery', 'disasters', 'disconcerting', 'discovertornad1', 'discussed', 'disease', 'disgusted', 'dismissal', 'disneyparks', 'disneyworld', 'display', 'disrupted', 'dissatisfaction', 'dissipated', 'distance', 'distastercleanup', 'distraction', 'distraught', 'district', 'dive', 'divided', 'divinity', 'division', 'dix', 'diy', 'djsenior1', 'dljcss', 'dm', 'dmg', 'dmt', 'dmv', 'dna', 'dobson', 'docmasse', 'documenting', 'dodged', 'doe', 'doesnt', 'dog', 'doing', 'dokie', 'dollar', 'domestic', 'domfruges', 'dominancei', 'dominant', 'dominican', 'donate', 'donating', 'dont', 'donut', 'door', 'dope', 'doppler', 'dopplerdan', 'dorm', 'dorney', 'doublej', 'dougkammerer', 'douse', 'dover', 'downed', 'downforget', 'downpour', 'downtown', 'downtownbrooklyn', 'dozen', 'dr', 'dragon', 'drain', 'drainage', 'drama', 'dramatic', 'dramylewin', 'drapes', 'draw', 'drawer', 'drdre', 'dread', 'dream', 'dreamed', 'drenchburg', 'drenched', 'drier', 'drill', 'drillsfire', 'drillshearing', 'drillshere', 'drillsi', 'drillsim', 'drillsnot', 'drillssex', 'drillsthe', 'drillstornado', 'drive', 'driver', 'driveway', 'driving', 'drone', 'drop', 'dropped', 'dropping', 'drought', 'drove', 'drown', 'drtonypastor', 'drug', 'drum', 'dsca', 'dseitzgop', 'duck', 'ducking', 'dulles', 'dumb', 'duncannon', 'dundalk', 'dundee', 'dunkinsville', 'duo', 'dupage', 'durham', 'durhamnc', 'dusty', 'duty', 'dye', 'dying', 'dynamic', 'dynamic1rookk', 'dynamite', 'dynamiting', 'eachamp', 'eagle', 'eaglezsol', 'earlier', 'early', 'earned', 'earth', 'earthquake', 'earthquakefire', 'earthquakeplaster', 'easier', 'easiertop', 'easily', 'east', 'eastcarolina', 'eastclearing', 'eastern', 'eastkywarn', 'eastland', 'easy', 'eat', 'eb', 'ebro', 'ecars', 'ecccweatheron', 'echo', 'economy', 'ecu', 'ecubaseball', 'ecupirateclub', 'ed', 'edge', 'edgy', 'edit', 'editorial', 'edna', 'edoggthered', 'edt', 'edt9', 'edtexpires', 'education', 'educrates', 'eerie', 'eerily', 'ef', 'ef1', 'effect', 'effective', 'effort', 'efiaodo1', 'efisherwx', 'ekyvost', 'el', 'elaine', 'elder', 'elect', 'electricity', 'electromagnetic', 'element', 'elementary', 'elgin', 'elijahweather', 'eliminate', 'elimination', 'elisaraffa', 'elite', 'elizabethtown', 'elizaville', 'elk', 'elkin', 'ellenkolb', 'elmhurst', 'elmos', 'elonmusk', 'em', 'email', 'emanating', 'embedded', 'emblem', 'emergency', 'emergencyprogramviewroyalca', 'emotion', 'emotional', 'emotionally', 'empireears', 'empirical', 'employee', 'empowering', 'enacted', 'encampment', 'encounter', 'encroach', 'end', 'endeavor', 'ended', 'endemic', 'ending', 'endorse', 'ene', 'energy', 'enforcement', 'engineering', 'enhanced', 'enjoy', 'enoch', 'ensley', 'ensure', 'entered', 'entire', 'entrance', 'entry', 'environment', 'environmental', 'environmentca', 'epidemic', 'epitome', 'equipment', 'eradicate', 'ericfink', 'erikaariasfox1', 'erinjh911', 'eroding', 'erthquakes', 'eruption', 'escambia', 'escape', 'escaping', 'escatawpa', 'ese', 'eshita', 'esmependergast', 'especially', 'espn', 'espousing', 'essential', 'essex', 'estate', 'esten', 'estimated', 'et', 'eta', 'etcjosh', 'etckpj', 'etobicoke', 'evacuate', 'evacuation', 'evanflood', 'evanwheaton', 'evened', 'evening', 'event', 'eventually', 'everybody', 'everyonei', 'everyones', 'evidence', 'evil', 'evolved', 'ewing', 'ewnielsen', 'exact', 'exactly', 'exaggeration', 'example', 'exceeds', 'exceptional', 'exchange', 'excited', 'excitement', 'excites', 'exciting', 'excuse', 'exec', 'executed', 'exhausted', 'exhibition', 'exhusband', 'exist', 'existed', 'exit', 'expanded', 'expect', 'expected', 'expecting', 'experience', 'experienced', 'experimental', 'expert', 'expired', 'explain', 'exploit', 'explore', 'explosion', 'explosive', 'export', 'exposed', 'extend', 'extended', 'extensive', 'extent', 'extinction', 'extinguish', 'extort', 'extreme', 'extremely', 'eye', 'f1', 'f9', 'face', 'facebook', 'faced', 'facility', 'facing', 'fact', 'factoid', 'faden', 'failed', 'fails', 'failure', 'fair', 'fairfax', 'fairhope', 'fairly', 'faith', 'fajitas', 'fall', 'fallen', 'falling', 'fallout', 'fallston', 'fam', 'famed', 'family', 'familyisforever', 'famine', 'famous', 'fan', 'fantasy', 'far', 'faring', 'farm', 'farmer', 'farmington', 'farmland', 'fartycheddarcat', 'fascinating', 'fast', 'faster', 'fatality', 'father', 'faulkateers', 'fault', 'faulty', 'favorite', 'fayette', 'fcc', 'fck', 'fcked', 'fckn', 'fdny', 'fear', 'fearless', 'fearn', 'feature', 'fed', 'feed', 'feel', 'feeling', 'fell', 'fella', 'fema', 'femadeanne', 'female', 'femaregion', 'fence', 'fennville', 'fentanyl', 'ferry', 'fest', 'field', 'fight', 'fighter', 'fightful', 'fighting', 'figure', 'figured', 'filming', 'filter', 'final', 'finale', 'finally', 'financing', 'finding', 'fine', 'fing', 'finish', 'finley', 'fireboat', 'fireboats', 'fired', 'firedamage', 'firegi', 'firesthey', 'fireyup', 'firstdownxos', 'fischer', 'fishing', 'fit', 'fitting', 'fl', 'flabbergasted', 'flag', 'flagstaff', 'flame', 'flash', 'flat', 'flatlands', 'flemingsburg', 'fleshed', 'flew', 'flfng', 'flight', 'flipped', 'float', 'flood', 'floodadvisory', 'floodare', 'floodcleanup', 'flooddamage', 'flooddisclosure', 'flooded', 'floodgeight', 'floodgive', 'floodgreat', 'floodgtflooded', 'floodgtparts', 'flooding', 'floodmitigation', 'floodnj', 'floodrisk', 'floods', 'floodsafety', 'floodsbut', 'floodtide', 'floodwashed', 'florida', 'floridamiramar', 'flowing', 'floyd', 'flprepares', 'fluid', 'flush', 'flwx', 'fly', 'flying', 'focused', 'focusing', 'foe', 'fold', 'folded', 'folk', 'folks', 'follow', 'followed', 'following', 'food', 'foodtalk', 'fool', 'fooled', 'foot', 'footage', 'football', 'foothill', 'forbergen', 'force', 'forced', 'forcentral', 'forecast', 'forecaster', 'forest', 'forever', 'forget', 'forgiving', 'forgot', 'fork', 'form', 'formed', 'forsouth', 'forsoutheastern', 'fort', 'fortheville', 'forum', 'foundation', 'fountain', 'fox', 'fox19', 'fox1news', 'foxdc', 'foxfriendsfirst', 'foxnews', 'foxnighteditor', 'foxtv', 'foxweather', 'franchise', 'francisco', 'frankford', 'franklin', 'fraud', 'freak', 'freaking', 'frederica', 'frederickmd', 'fredstoneflint', 'free', 'freedom', 'freely', 'freeport', 'freeway', 'freeze', 'freezeused', 'frequent', 'fresh', 'freshman', 'fri', 'friday', 'fridayfull', 'friend', 'friends', 'frightening', 'frincerry', 'frontroyal', 'frost', 'ft', 'ftw', 'fuca', 'fuck', 'fucked', 'fuckin', 'fucking', 'fuckyourgunrights', 'fuel', 'fukushima', 'fulfilling', 'fully', 'fulton', 'fun', 'functioning', 'fund', 'fundamental', 'funding', 'funnel', 'funnelfiasco', 'furthermore', 'future', 'fuuuuuck', 'fwh', 'ga', 'gabygoldberg', 'gaffney', 'game', 'gamemustangs', 'games', 'gaming', 'gap', 'garage', 'garbage', 'garden', 'garfield', 'garner', 'garrett', 'gartnerinc', 'garvin', 'gas', 'gasping', 'gaston', 'gate', 'gated', 'gatesethan', 'gather', 'gatorsbb', 'gatos', 'gave', 'gawd', 'gawx', 'gay', 'gaylord', 'gayrights', 'gcm', 'gear', 'geared', 'geeknerd1matt', 'geldingadalir', 'general', 'generation', 'genesis', 'geoffhaxton', 'george', 'georgebalekji', 'georgetown', 'georgia', 'georgiafan1', 'germanton', 'getin', 'getting', 'geyser', 'ghana', 'ghanaians', 'ghost', 'gif', 'gifs', 'gimme', 'gingerzee', 'girl', 'girlwas', 'girly', 'given', 'giving', 'glad', 'glampinghub', 'glancy', 'glass', 'glassandrews', 'glasscock', 'glen', 'glendale', 'global', 'gm', 'goal', 'goalie', 'goat', 'god', 'godbless', 'goddamn', 'going', 'golden', 'gone', 'gonna', 'gonzalez', 'good', 'goode', 'goodmorning', 'goody', 'google', 'goooooooooood', 'gop', 'gopchairwoman', 'gorgeous', 'gosh', 'got', 'gotornado', 'gotta', 'gov', 'govbilllee', 'government', 'governor', 'govt', 'gps', 'gr', 'grab', 'grabbed', 'grad', 'grade', 'grader', 'graduated', 'graduation', 'graf', 'grandpa', 'grant', 'graphic', 'grass', 'grateful', 'gravel', 'gravemind', 'graveor', 'gray', 'great', 'greatchileanearthquake', 'greater', 'green', 'greenish', 'greensboro', 'greenup', 'greenwich', 'greenwood', 'greg', 'gregabbotttx', 'gregobrien9', 'grenadier', 'grew', 'grey', 'grid', 'grievance', 'grieving', 'griffinthefolf', 'griffithville', 'grill', 'grim', 'grind', 'grocery', 'ground', 'grove', 'growing', 'grown', 'growth', 'gt', 'gt9', 'gtgt', 'guard', 'guardian', 'guardiansofthegalaxy', 'guess', 'guided', 'guilford', 'gulf', 'gun', 'guncontrol', 'guncontrolnow', 'gunfire', 'gunloving', 'gunman', 'gunned', 'gunviolence', 'gupsengun', 'gust', 'gustnados', 'gusty', 'gutter', 'guy', 'guyeither', 'gwc', 'gyllenhaal', 'ha', 'haappai', 'haappais', 'hack', 'haddonfield', 'hadnt', 'haha', 'hail', 'hailey', 'hailstorm', 'haiti', 'halabuckwset', 'haldonahue', 'haley', 'half', 'hall', 'hallway', 'halo', 'hamilton', 'hammer', 'hancock', 'hand', 'handgun', 'handle', 'handled', 'hanging', 'hanover', 'hanxu1', 'haphazard', 'happen', 'happened', 'happening', 'happens', 'happensbullshit', 'happy', 'harbor', 'hard', 'hardened', 'harder', 'harford', 'harlan', 'harmony', 'harper', 'harrisburg', 'harrison', 'harrystylestickets', 'hashtag', 'hasta', 'hatchet', 'hate', 'hating', 'haunt', 'havent', 'having', 'hayden', 'haywood', 'haz', 'hazard', 'hazardtornadoweathernation', 'hb', 'head', 'headed', 'heading', 'headquarters', 'healing', 'health', 'heap', 'hear', 'heard', 'heardle', 'hearing', 'heart', 'heartbroken', 'heat', 'heatherthomasaf', 'heaven', 'heaviest', 'heavily', 'heavy', 'heck', 'hedman', 'heflin', 'height', 'heimlich', 'held', 'helicopter', 'hell', 'hella', 'hellhe', 'hello', 'help', 'helped', 'helping', 'henry', 'herd', 'heroic', 'herschel', 'hertz', 'hesitation', 'hey', 'heyleia', 'hickory', 'hiddenite', 'hiddennamebc', 'hiding', 'high', 'higher', 'highest', 'highland', 'highly', 'highsmith', 'hightstown', 'highway', 'hill', 'hillsboro', 'hire', 'historical', 'history', 'hit', 'hllo1', 'hoax', 'hockey', 'hog', 'hold', 'hole', 'holiday', 'holla', 'holleman', 'hollow', 'holly', 'hollyisloud', 'hollywood', 'holy', 'home', 'homeits', 'homeless', 'homeowner', 'homerepair', 'homes', 'homesweethome', 'hometown', 'homewood', 'honestly', 'honor', 'honored', 'hood', 'hook', 'hooking', 'hope', 'hoped', 'hopefully', 'hoping', 'hopkins', 'horizon', 'horrible', 'horrifying', 'horror', 'horry', 'horse', 'hospital', 'hostage', 'hosted', 'hot', 'hour', 'hours', 'house', 'housewife', 'housing', 'houston', 'houstonrockets', 'howard', 'howl', 'hr', 'hrbullsbaseball', 'hrflood', 'hrhsbulls', 'hrrr', 'hub', 'hudson', 'huffmanweather', 'huffmanweatherservice', 'huge', 'hughesville', 'huh', 'human', 'humanitarian', 'humid', 'hunga', 'hunger', 'hungry', 'hunkered', 'hunter', 'hunting', 'huntington', 'huntingtown', 'hurdle', 'hurricane', 'hurricaneearthquake', 'hurricanes', 'hurricaneseason', 'hurricaneslightning', 'hurricanesrangers', 'hurricanestacy', 'hurricaneville', 'hurt', 'hurtno', 'hvward', 'hwssevere', 'hwy', 'hyattnhou', 'hybrid', 'hydroottawa', 'hydroplaning', 'i9', 'ia', 'iabeginning', 'iahssoc', 'iawx', 'ib', 'ibelievejohnnydepp', 'ice', 'iceand', 'icedknife', 'id', 'ida', 'idaho', 'idc', 'idea', 'ideasoficefire', 'idiocy', 'idiot', 'idjits', 'idk', 'idkw', 'idwx', 'ig', 'iiaa', 'ik', 'ike', 'il', 'il1', 'ill', 'illegal', 'illinois', 'illness', 'illusion', 'ilmarinen', 'ilwx', 'im', 'image', 'imagine', 'imma', 'immediately', 'immigrant', 'immigrants', 'immunity', 'imo', 'impact', 'impacted', 'impacting', 'impassable', 'impeded', 'implement', 'implicating', 'important', 'importanta', 'impressed', 'impressiv', 'impressive', 'imryanphelps', 'inaction', 'inbox', 'inception', 'inch', 'incident', 'include', 'included', 'includes', 'includevanishmethodwealthy', 'including', 'incluye', 'income', 'incoming', 'inconvenience', 'incorrect', 'increase', 'increasing', 'incredible', 'incredibly', 'ind', 'independent', 'independentartist', 'indian', 'indiana', 'indianaillinois', 'indianapolis', 'indicated', 'indicates', 'indicator', 'indie', 'industry', 'indy', 'inear', 'ineveryone', 'infamous', 'infant', 'infinite', 'inflation', 'inflow', 'info', 'inform', 'information', 'infringed', 'infuriating', 'inhaler', 'inher', 'initial', 'inj', 'injured', 'injury', 'inning', 'innocence', 'innocent', 'innovative', 'innsbrook', 'insane', 'insanely', 'insanity', 'inside', 'insignificant', 'inspect', 'inspection', 'inspiring', 'instagram', 'instead', 'institution', 'institutionalized', 'instructing', 'insurance', 'insuranceourbusiness', 'insurmountable', 'intended', 'intense', 'intent', 'interact', 'intercept', 'interchange', 'interested', 'interesting', 'interior', 'interna', 'international', 'internationally', 'interrupted', 'interrupting', 'intersect', 'intersection', 'interstate', 'interview', 'intruder', 'intrudersand', 'investigation', 'investigator', 'invited', 'inviting', 'involving', 'inwx', 'iowa', 'iq', 'irate', 'iredell', 'iron', 'irrefutably', 'irrr', 'irvine', 'isdub', 'island', 'isnt', 'isolated', 'issue', 'issued', 'italy', 'itd', 'itdiscovering', 'itstop', 'itwhere', 'ive', 'ivy', 'iwriteok', 'iykyk', 'jackass', 'jackets', 'jackson', 'jacksonville', 'jake', 'jakecrain', 'jakehansen', 'jalen', 'jamaica', 'james', 'jamesfromcourt', 'jampacked', 'jan1kkk', 'jane', 'janellewaz', 'janicehuffny', 'jaramogi', 'jarrell', 'jasonboyerwlos', 'jasper', 'jawdropping', 'jawja1', 'jay', 'jaycaspiankang', 'jc', 'jdhuffmanhws', 'jefferson', 'jeffpudlinski', 'jenmsft', 'jennbnews', 'jennings', 'jenwilliams', 'jericho', 'jersey', 'jesse', 'jesus', 'jet', 'jett', 'jgoldmannj', 'jim', 'jimcantore', 'jimmacpam', 'jimmy', 'jimrome', 'jkw', 'jlosey', 'joagav', 'job', 'joe', 'joebiden', 'joel', 'johnmsides', 'johnnydepp', 'johnston', 'join', 'joke', 'joker', 'jonathanchait', 'jones', 'jonesville', 'jonmrob', 'joplin', 'jordanwolfewx', 'jorgecham', 'jose', 'joshuaogundu', 'journey', 'joyturns', 'joyurcaba', 'jpeters', 'jpfinlaynbcs', 'jpmusiclvr', 'jr', 'jsho', 'juan', 'juddlegum', 'judge', 'judy', 'juicy', 'juicyju', 'julialeblanctv', 'julielkenward', 'july', 'julzroze', 'june', 'junior', 'jurisdiction', 'jus', 'just', 'justice', 'justifiably', 'justify', 'justintrudeau', 'jvgindyvoter', 'jvlast', 'jwheelerwavy', 'jwxman', 'kaeidoscope', 'kaeshamarie', 'kaitlynmcgrath', 'kakenews', 'kallgren', 'kane', 'kansa', 'kansas', 'kanye', 'kap', 'kara', 'karathompsonwx', 'kardashgoddess', 'karen', 'kasey', 'kateboicourt', 'kathyfish', 'kathypeek', 'katiecolletttv', 'katrina', 'katystoll', 'kawaiitornado', 'kb9lxh', 'kcjj', 'kckingmike', 'kco1', 'kearney', 'kearny', 'kecs1', 'keeping', 'keepkidssafe', 'kek', 'kellismith1', 'kenner', 'kent', 'kentucky', 'kentuckyweather', 'kepler', 'kept', 'kerr', 'kerrence', 'kerryhowley', 'ketcorrine', 'ketteringbr', 'kevinmyattwx', 'kevlar', 'key', 'kg', 'khloekardashian', 'kick', 'kid', 'kidding', 'kilby', 'kill', 'killed', 'killer', 'killing', 'kiln', 'kim', 'kind', 'kinda', 'kindergarten', 'king', 'kingman', 'kingsdominionva', 'kingsmtn', 'kingsofdastreet', 'kingstown', 'kinksall', 'kinluney', 'kiryano', 'kit', 'kitchen', 'kittennskyy', 'km', 'kmactwn', 'kmh', 'kmneun', 'knew', 'knife', 'knightdale', 'knocked', 'know', 'knowing', 'knowledge', 'known', 'knox', 'kolaches', 'kootenaygreg', 'kopperston', 'krossjean', 'kswx', 'kumbaya', 'kvue', 'ky', 'kylewatsonwx', 'kyweatherweenie', 'kywx', 'la', 'lacentral', 'lack', 'lacombe', 'lacrosse', 'ladder', 'laden', 'lady', 'ladydogebugbird', 'ladyjustice91', 'ladysmith', 'lafayette', 'lafd', 'lafdalert', 'lafourche', 'lake', 'lakh', 'lakotaman1', 'lamars', 'land', 'landfill', 'landor', 'landslide', 'landspout', 'lane', 'laplace', 'laplata', 'larchwood', 'large', 'largest', 'largo', 'lasted', 'late', 'later', 'latertweet', 'latest', 'latimes', 'latlon', 'lattimore', 'laundry', 'laurel', 'laurens', 'laurenzenzietv', 'lavender', 'law', 'lawindsor', 'lawnrainy', 'lawrence', 'lawsuit', 'lay', 'laying', 'lazy', 'lb', 'lcmc', 'ldfgm', 'le', 'lead', 'leaddata', 'leader', 'leadermcconnell', 'leadership', 'leading', 'league', 'leak', 'leake', 'learn', 'learned', 'learning', 'leave', 'leaving', 'lebron', 'lee', 'leesburg', 'leetyler', 'left', 'legal', 'legalized', 'legends', 'legislation', 'legislator', 'legit', 'legitimate', 'leilii', 'length', 'lengthy', 'leslieplynn', 'lesser', 'lesson', 'lessthanjake', 'lester', 'let', 'lets', 'letsgocanes', 'letter', 'letting', 'levee', 'level', 'levelmay', 'levy', 'lgbtiq', 'lgbtq', 'liberty', 'library', 'licker', 'lie', 'lies', 'life', 'lifealtering', 'lifestyle', 'lifetime', 'lifted', 'light', 'lighter', 'lightest', 'lightning', 'liguoris', 'lik', 'like', 'likefor', 'likely', 'lily', 'limb', 'limit', 'lincoln', 'lincolnshire', 'lincolnton', 'lindenwold', 'line', 'link', 'linked', 'linwood', 'lip', 'lipscomb', 'lisalouu', 'list', 'listen', 'listening', 'lister', 'lit', 'literal', 'literally', 'little', 'littleelvis', 'littlenikki', 'live', 'lived', 'livein', 'living', 'livonia', 'ljsdon', 'lllllllllls', 'lmao', 'lmaoo', 'load', 'loan', 'lobby', 'lobbyist', 'local', 'localagents', 'locally', 'localyokelwx', 'located', 'location', 'lock', 'lockdownsi', 'locked', 'locker', 'lodi', 'logical', 'lol', 'lombard', 'london', 'long', 'longer', 'longhurst', 'longterm', 'longtrack', 'look', 'lookin', 'looking', 'lookout', 'loop', 'loosen', 'lord', 'lori1', 'lorifox9', 'loris', 'los', 'lose', 'losing', 'loss', 'lost', 'lot', 'lou', 'loud', 'louder', 'louis', 'louisa', 'louisiana', 'love', 'loved', 'loveits', 'lovelylancel', 'lovelymilian', 'lovingston', 'low', 'lowaterkeeper', 'lowend', 'lower', 'lowering', 'lowest', 'lowestfloor', 'lowkey', 'lowlevel', 'lsr', 'lubbock', 'lucha', 'luck', 'lucky', 'luke', 'luling', 'lumberton', 'lunch', 'luxurious', 'lying', 'lynchburg', 'lyon', 'm1', 'm11', 'm9', 'ma', 'mabelton', 'machine', 'machinery', 'macsbtbash', 'mad', 'madawaska', 'madfarmer', 'madison', 'madness', 'mag', 'maggarooo', 'magic', 'magician', 'magnitude', 'magnolia', 'maiden', 'mailbox', 'main', 'mainly', 'major', 'majorbirmingham', 'make', 'makeover', 'maker', 'making', 'mall', 'mamalizmcg', 'man', 'manage', 'management', 'manager', 'manakin', 'mangroves', 'manitoba', 'manmade', 'manufacture', 'manufactured', 'manufacturer', 'map', 'mar', 'march', 'marciabunney', 'marcorubio', 'marcryanonair', 'margaretmariel', 'marginal', 'maribe11a', 'mark', 'markbaden', 'marked', 'market', 'marketplace', 'marlton', 'marnewilson', 'marry', 'marshal', 'marshall', 'marsing', 'martinsville', 'marwilliamson', 'mary', 'marydell', 'maryland', 'marylandeast', 'marylandnorth', 'marypoppins', 'marysville', 'masdogwx', 'mason', 'mass', 'massacre', 'massive', 'master', 'match', 'mater', 'matt', 'matter', 'max', 'maximum', 'maybe', 'maydaymindy9', 'mayor', 'maze', 'mcbride', 'mccalliebseball', 'mcclusky', 'mccord', 'mccracken', 'mcdowell', 'mcfslaw', 'mclean', 'md', 'md1', 'mdt', 'mdwx', 'meadow', 'meadville', 'mean', 'meaning', 'meant', 'measured', 'measuring', 'mecklenburg', 'medeana', 'mediaite', 'mediapolis', 'mediation', 'medicare', 'medication', 'medicine', 'medium', 'meekly', 'meet', 'meeting', 'meherrin', 'mejenwalton', 'meldrum', 'mellott', 'melt', 'member', 'memorable', 'memorial', 'memorialday', 'men', 'menacing', 'menghostone', 'mental', 'mentally', 'mention', 'mentioning', 'merch', 'merchandise', 'mercury', 'mereta', 'merfradio', 'merica', 'mesoanalysis', 'mesovortex', 'message', 'messing', 'messy', 'met', 'metairie', 'metal', 'meteorologist', 'meteorology', 'methboiswag', 'methodwhen', 'metro', 'mexico', 'mf', 'mi', 'miamakeupartist', 'miami', 'michael', 'michael1x', 'michaelheimlich', 'michaelsteele', 'michigan', 'michigantech', 'michudalls', 'miciahbay', 'micky', 'microburst', 'microphone', 'mid', 'midday', 'middle', 'middlesboro', 'midland', 'midmichigan', 'midnight', 'midwest', 'mightve', 'miguel', 'mile', 'milford', 'militarized', 'military', 'milking', 'millennium', 'miller', 'million', 'millionshenry', 'milwaukee', 'mina', 'mind', 'mindset', 'mini', 'minimum', 'minneapolis', 'minor', 'minter', 'minus', 'minuscule', 'minute', 'miracle', 'miss', 'missed', 'missing', 'mississippi', 'missouri', 'mistake', 'mistaken', 'mitigate', 'mitigation', 'mivysgift', 'miwx', 'mixed', 'mkr1', 'ml', 'mlb', 'mls', 'mmm', 'mn', 'mngr', 'mo', 'mobile', 'mode', 'model', 'modeling', 'moderate', 'moines', 'moisture', 'mojomoomey', 'mold', 'mollyjongfast', 'mom', 'moment', 'momsforsj', 'mon', 'monday', 'moneta', 'money', 'monitoring', 'monoblancoatx', 'monroe', 'monsoon', 'monster', 'montebello', 'montezuma', 'montgomery', 'month', 'monticello', 'montpelier', 'montreal', 'moon', 'moonboy', 'moore', 'moored', 'mooring', 'moravian', 'morgan', 'morgankolkmeyer', 'morgue', 'mormon', 'morning', 'moronic', 'mortar', 'mortified', 'morton', 'mortontx', 'moss', 'mother', 'mothernature', 'motivate', 'motivatefenty', 'mount', 'mountain', 'mourner', 'mourning', 'mouth', 'moved', 'movie', 'movieendorser', 'moving', 'mow', 'mowing', 'mph', 'mphanother', 'mping', 'mramponsem', 'mrgoalie', 'mrmeeyoung', 'ms', 'msg', 'msr', 'mstodaynews', 'msuweather', 'mswx', 'mt', 'mta', 'mtgconspiracy', 'mtn', 'mud', 'multiple', 'mural', 'murder', 'murdered', 'murica', 'murky', 'murmur', 'murphtwn', 'museum', 'music', 'musicislife', 'musicman99x', 'muzzle', 'mvp', 'mwf', 'mystateline', 'mzdeevah1', 'mzdivah', 'naemt', 'nahhh', 'nani', 'nanih', 'napa', 'narrow', 'nashville', 'nasty', 'natashaghoskins', 'natecohn', 'nathaliejacoby1', 'nation', 'national', 'nationalhockeyleagues', 'nationwide', 'native', 'nats', 'natural', 'naturaldisaster', 'nature', 'navigate', 'navigation', 'navy', 'naw', 'nazca', 'nbc1', 'nbc9', 'nbcchicago', 'nbcnews', 'nbcstormteam', 'nbcwashington', 'nc', 'ncga', 'ncwx', 'nd', 'ne', 'near', 'nearby', 'nearest', 'nearing', 'nearly', 'nebraska', 'necessary', 'necessity', 'neches', 'need', 'needed', 'needing', 'negative', 'negotiable', 'neighbor', 'neighborhood', 'nelson', 'nerve', 'nervewracking', 'nervous', 'neshoba', 'nesn', 'net', 'nevada', 'new', 'newark', 'newd', 'newintern', 'newjersey', 'newmusic', 'newport', 'newprofilepic', 'news', 'newsdc', 'newspaper', 'newton', 'newtown', 'newx', 'newyork', 'nextlevel', 'nfl', 'nftcommunity', 'nftnoahsark', 'nfts', 'nice', 'nicely', 'nicetown', 'nichols', 'nickvrusso', 'nifty', 'nigga', 'night', 'nightearthquakes', 'nilwxreports', 'nj', 'njeastern', 'njrockland', 'njwx', 'nmsscreenshots', 'nne', 'nnw', 'noah', 'noahhiles', 'nominate', 'nominated', 'nonemergency', 'nonetheless', 'nonexistencesleep', 'noon', 'nope', 'nopeim', 'noquitinny', 'noraneus', 'norcross', 'norm', 'normal', 'norman', 'normanwx', 'north', 'northampton', 'northbrook', 'northeast', 'northeastern', 'northern', 'northsideish', 'northwest', 'northwestern', 'northwoodu', 'notable', 'note', 'noted', 'notice', 'noticed', 'notification', 'notified', 'noting', 'notoriously', 'notthrealgreeny', 'noxapater', 'np', 'npp', 'nr', 'nra', 'nrabloodmoney', 'nraconvention', 'nrc', 'nssl', 'nuclear', 'nuclearkirk', 'number', 'numerous', 'nupp', 'nurses', 'nut', 'nw', 'nws', 'nwsamarillo', 'nwsbaltwash', 'nwsblacksburg', 'nwschicago', 'nwsgsp', 'nwsiln', 'nwsjacksonky', 'nwslubbock', 'nwsmemphis', 'nwsmiami', 'nwsmobile', 'nwsmountholly', 'nwsowlieskywarn', 'nwsquadcities', 'nwssanangelo', 'nwsstatecollege', 'nwstornado', 'nwswakefieldva', 'nwswichita', 'ny', 'nyc', 'nycolebrittney', 'nycsouthpaw', 'nyliberty', 'nyr', 'nysamajority', 'nytimes', 'nyuntil', 'oak', 'oakland', 'oaklevel', 'oat', 'oatt', 'oaxaca', 'ob', 'oberlin', 'obiba', 'object', 'observer', 'obtaining', 'obvious', 'occasional', 'occupant', 'occupynra', 'occur', 'occured', 'occurred', 'occurring', 'ocean', 'oceana', 'oceans', 'october', 'oddly', 'ode', 'odell', 'offer', 'offering', 'offfromport', 'office', 'officer', 'official', 'officially', 'offset', 'ofizilla', 'og', 'oh', 'ohara', 'ohare', 'ohareairport', 'ohcurrently', 'ohin', 'ohio', 'ohwx', 'oil', 'oiler', 'oilersavalanche', 'oilersflames', 'ok', 'okaaay', 'okay', 'okie', 'oklahoma', 'oklahomain', 'okolona', 'okwx', 'okx', 'old', 'oldest', 'ole', 'oliver', 'oliverkent9', 'olney', 'olsen', 'omg', 'ominous', 'onchainbigbrain', 'oneunderscore', 'onewe', 'ongoing', 'onky', 'online', 'onramp', 'onstorm', 'ontario', 'ontbaseball', 'onthisday', 'ontx', 'oommens', 'oozyswonzy', 'open', 'opencapitalweather', 'opened', 'opening', 'openness', 'operating', 'operator', 'opinion', 'opium', 'opportunity', 'opposing', 'opposite', 'optical', 'option', 'orangeburg', 'orchard', 'orchestral', 'order', 'oreboundimages', 'organization', 'orientation', 'origin', 'orleans', 'orrr', 'oscar', 'otg', 'otsegoclub', 'otter', 'ottnews', 'outbreak', 'outbuilding', 'outdoors', 'outdoortype', 'outflow', 'outfuck', 'outgunned', 'outlet', 'outlined', 'outside', 'outskirt', 'outta', 'ovcsports', 'overdue', 'overflowing', 'overhead', 'overnight', 'overwatered', 'owner', 'owyhee', 'oxygen', 'ozark', 'pa', 'pabeen', 'pace', 'pack', 'package', 'packed', 'pad', 'paducah', 'page', 'paigeewing', 'pain', 'paint', 'painted', 'painting', 'paintinstagram', 'palashkamal', 'palma', 'panchico', 'pandemic', 'pandemicrelated', 'panhandle', 'panic', 'panicked', 'pannlewis', 'pap', 'paper', 'paradise', 'parent', 'parentchild', 'parguera', 'parish', 'park', 'parke', 'parkerjayp', 'parkfield', 'parking', 'parlay', 'partial', 'partially', 'participate', 'particuarly', 'particularly', 'partlymostly', 'party', 'partying', 'pas', 'pascagoula', 'pass', 'passaic', 'passed', 'passenger', 'passiac', 'passing', 'past', 'path', 'patient', 'patrick', 'patrol', 'pattonoswalt', 'patty', 'paulwartenberg', 'pause', 'pavanfederico', 'paw', 'pawx', 'pay', 'paymaster', 'payment', 'pbcdem', 'pbcfr', 'pbcountysheriff', 'pd', 'pdcbaseball', 'pdt', 'peace', 'peacefully', 'peak', 'pearl', 'pearson', 'peeled', 'peep', 'pen', 'pennsylvania', 'pennyand', 'pensacola', 'pensacolaferry', 'pentecost', 'people', 'pepperoni', 'perfect', 'perfectly', 'perk', 'perkins', 'permission', 'perpetuate', 'perry', 'persimmon', 'persistent', 'person', 'personal', 'personally', 'perspective', 'peru', 'pervasive', 'pestilence', 'pete', 'peter', 'petition', 'petty', 'pfur1', 'pghguyinva', 'phone', 'photo', 'photograph', 'photographer', 'photosvideos', 'phrase', 'physical', 'pic', 'pickup', 'picture', 'pictured', 'piece', 'pierre', 'pierrepoilievre', 'pig', 'pigeon', 'pike', 'pile', 'pilfer', 'pill', 'pillow', 'pilot', 'pine', 'pineville', 'piney', 'pinnacle', 'pint', 'pipe', 'pirps19', 'pistol', 'pit', 'pl', 'place', 'placed', 'plague', 'plain', 'plaines', 'plan', 'plane', 'planet', 'plant', 'plantation', 'plantingflooddrought', 'plate', 'play', 'playbook', 'played', 'player', 'playoff', 'playoffs', 'pleasant', 'pleased', 'plenty', 'plns', 'plot', 'plush', 'pm', 'pmlook', 'pmnighttheres', 'pns', 'po', 'poala', 'pocatello', 'pockt', 'podcast', 'point', 'pointor', 'poisoning', 'pole', 'police', 'policy', 'political', 'politician', 'politicize', 'politico', 'poll', 'polygon', 'pomurray', 'pond', 'pontifex', 'ponza', 'poorly', 'pop', 'popping', 'popular', 'porch', 'port', 'porter', 'portfolio', 'portion', 'portsmouth', 'pose', 'position', 'positive', 'possible', 'possibly', 'post', 'posted', 'postfade', 'postgame', 'posting', 'postmaster', 'postponed', 'potential', 'potentially', 'potomac', 'potus', 'pour', 'poured', 'pourover1', 'power', 'powerful', 'powerless', 'powerlines', 'powhatan', 'ppl', 'practice', 'practiced', 'practicing', 'practing', 'prairie', 'pray', 'prayer', 'prayers', 'prayersforuvalde', 'praying', 'prayuvalde', 'preborn', 'precise', 'predatory', 'predict', 'predictable', 'predicted', 'preference', 'preferred', 'prelim', 'preliminary', 'premature', 'preparation', 'prepare', 'prepared', 'preparedness', 'preparing', 'prereggae', 'presbyterian', 'present', 'presented', 'president', 'press', 'presser', 'pressure', 'prestige', 'pretending', 'prettier', 'pretty', 'prevent', 'preventative', 'prevented', 'preview', 'previous', 'previously', 'price', 'pride', 'primarily', 'primary', 'princessbravato', 'princethe', 'principal', 'prior', 'priority', 'private', 'probability', 'probably', 'problem', 'problemstop', 'process', 'produce', 'produced', 'producing', 'product', 'profession', 'profile', 'profit', 'program', 'programming', 'progress', 'project', 'prolifemyass', 'prolifepolitics', 'prominent', 'promise', 'prompting', 'prone', 'proof', 'propaganda', 'proper', 'property', 'proponent', 'prospect', 'protect', 'protecting', 'protection', 'protective', 'protects', 'protest', 'protesting', 'proud', 'prove', 'provenauthority', 'provide', 'provided', 'psychopath', 'ptboexaminer', 'public', 'publicsafety', 'published', 'puck', 'puerto', 'puffy', 'puked', 'pull', 'pulled', 'pump', 'pumping', 'pumps', 'pungentpickle', 'punk', 'pup', 'pupadhyaya', 'purchase', 'purchased', 'puroclean', 'purple', 'push', 'pushed', 'putting', 'pylesville', 'qb', 'qlcs', 'quake', 'quakes', 'qualifying', 'quantico', 'quantum', 'quarter', 'queen', 'queencitynews', 'quentinball', 'question', 'quick', 'quickly', 'quiero', 'quite', 'quitting', 'race', 'rachelfrankct', 'rachpiscitelli', 'racism', 'racist', 'radar', 'radarscope', 'radiation', 'radio', 'radiofreetom', 'rage', 'ragged', 'raginridgefb', 'raidger', 'rail', 'railway', 'rain', 'rainbow', 'rainbowafterthestorm', 'rainfall', 'raining', 'rainsbecause', 'rainsmall', 'rainwrapped', 'raising', 'raisingtheridge', 'raleigh', 'raleighgov', 'raleighwx', 'ran', 'randleman', 'random', 'randomly', 'ranger', 'rangers', 'rap', 'rape', 'rapid', 'rapidly', 'rapper', 'rare', 'rarely', 'rarenreal', 'rate', 'rated', 'rates', 'rating', 'rational', 'ravenna', 'raw', 'raygrape', 'rayjortega', 'raysbaseball', 'rbi', 'rd', 'reach', 'reached', 'reacting', 'reaction', 'reactor', 'read', 'reading', 'ready', 'readyto', 'real', 'realamberheard', 'reality', 'realize', 'realized', 'really', 'realrockerman9', 'realronhoward', 'rear', 'reason', 'rebellion', 'rebuild', 'rebuilt', 'recalibrate', 'recall', 'receded', 'receding', 'received', 'recent', 'recently', 'recipient', 'recliner', 'recognizable', 'recollection', 'record', 'recorded', 'recording', 'recover', 'recovers', 'recruit', 'red', 'redeeming', 'redidential', 'redirecting', 'redkyaresdistrict9', 'redriver', 'redrosesenshi', 'reduce', 'redwater', 'reedtimmeraccu', 'referral', 'referring', 'refers', 'reflectivity', 'reform', 'refugee', 'regarding', 'regardless', 'region', 'regional', 'register', 'registration', 'regular', 'regulation', 'rejection', 'related', 'relating', 'relationship', 'relatively', 'released', 'relief', 'relieve', 'rely', 'remain', 'remained', 'remains', 'remember', 'remind', 'reminded', 'reminds', 'remington', 'removed', 'render', 'renfroe', 'reno', 'renopiedmont', 'renovated', 'rent', 'rental', 'renter', 'renting', 'reopens', 'rep', 'repair', 'repdemi', 'replace', 'replaced', 'report', 'reported', 'reporter', 'reporting', 'represent', 'representative', 'repstaats', 'reptroycarter', 'republic', 'republican', 'republicans', 'republicansaredestroyingamerica', 'republicansaretheproblem', 'repugnantins', 'repurposed', 'request', 'require', 'required', 'requirement', 'rescue', 'research', 'researcher', 'resemble', 'reserve', 'reserved', 'residence', 'resident', 'residential', 'resilient', 'resin', 'resource', 'respond', 'responder', 'responding', 'response', 'responsibility', 'responsible', 'rest', 'restaurant', 'reston', 'restriction', 'result', 'resulted', 'resulting', 'retarded', 'retiringmichael', 'returned', 'revealing', 'revenue', 'review', 'reviewed', 'revival', 'rewind', 'reykjanes', 'rfd', 'rgamez', 'rhis', 'rhyming', 'rib', 'rice', 'rich', 'richland', 'richmond', 'rickmayervinyl', 'ricktompkins', 'ricky', 'rico', 'ride', 'ridiculous', 'rifle', 'right', 'rightit', 'rightwing', 'rih', 'riker', 'rikkelle', 'ring', 'riot', 'rise', 'riseresilience', 'rising', 'risk', 'ritter', 'rivalry', 'river', 'rivercreek', 'riyankaganguly', 'rly', 'rn', 'road', 'roadlane', 'roadway', 'roamed', 'roblox', 'robot', 'rochelle', 'rock', 'rockies', 'rockthesetweets', 'rocky', 'rod', 'rodneyg', 'rof', 'roll', 'rolled', 'rolling', 'romanbaber', 'rondesantisfl', 'ronjohnson', 'roof', 'room', 'roostmalcolm', 'rosa', 'rosie', 'ross', 'rotate', 'rotating', 'rotation', 'rough', 'round', 'route', 'row', 'roxboro', 'royal', 'rtdnacanada', 'ruble', 'rude', 'rugrats', 'ruined', 'ruinous', 'rule', 'ruled', 'run', 'running', 'rural', 'rush', 'russian', 'rutherford', 'rv', 'rva', 'rvawx', 'rville', 'rwtv', 'ryanhallyall', 'ryanmillerwx', 'ryanwx', 'saarshen', 'sac', 'sad', 'saddle', 'sadly', 'safe', 'safest', 'safety', 'safetyfirst', 'sagittarius', 'said', 'saidhurrocane', 'saint', 'saintfranciscantprotectyouformuchlonger', 'saintjeanbaptiste', 'saintsfan', 'sake', 'salary', 'sale', 'salmonella', 'salt', 'salvation', 'samething', 'sammmidd', 'samsampieri', 'samstein', 'san', 'sandwiched', 'sandy', 'sane', 'sanitizer', 'santa', 'santee', 'sargez', 'sasa', 'saskatchewan', 'sat', 'saturday', 'saturdaythe', 'sauna', 'savannabritowx', 'save', 'saved', 'saveourchildren', 'savvymia', 'saw', 'sawmill', 'say', 'sayin', 'saying', 'sb11', 'sc', 'scaggsville', 'scale', 'scan', 'scanning', 'scare', 'scared', 'scariest', 'scarlet', 'scary', 'scattered', 'scdot', 'scenario', 'scene', 'schnebley', 'school', 'schooler', 'schooling', 'schoolshooting', 'schooltornado', 'schuyler', 'science', 'scientist', 'scobie', 'scoot', 'score', 'scotch', 'scottsville', 'scottypowellwx', 'scrape', 'screaming', 'screen', 'screenshot', 'scrolling', 'scud', 'scwx', 'sd', 'se', 'sea', 'seagrove', 'seal', 'sealevelrise', 'search', 'season', 'seasonand', 'seat', 'seattlestorm', 'sec', 'seclude', 'second', 'secondround', 'secondsfelt', 'section', 'sector', 'securing', 'security', 'seductive', 'seeing', 'seek', 'seen', 'segment', 'segmentnon', 'seibert', 'self', 'selfie', 'sell', 'selling', 'semi', 'semiauto', 'semifinal', 'seminar', 'sen', 'senategop', 'senator', 'senatoramr', 'send', 'sending', 'sends', 'senior', 'senschumer', 'sense', 'senseless', 'senselessness', 'sensibly', 'sensor', 'sent', 'sentedcruz', 'sentthe', 'sephiroth', 'september', 'sequel', 'serf', 'series', 'seriously', 'served', 'service', 'session', 'set', 'sethamandel', 'setting', 'setup', 'seven', 'severe', 'severethunderstorms', 'severeweather', 'severewx', 'severn', 'sewage', 'sewageand', 'sex', 'seymour', 'sfmagicmountain', 'shadesofvan', 'shadowed', 'shady', 'shaft', 'shailkhiyara', 'shake', 'shaken', 'shakira', 'shall', 'shame', 'shannon', 'shannonrwatts', 'shaped', 'share', 'sharecab', 'shared', 'sharkcanomovie', 'sharknado', 'shawn', 'shear', 'shebreathesfire', 'shed', 'sheetz', 'shelby', 'shelf', 'shelter', 'shelterand', 'sheltering', 'shes', 'shift', 'shifting', 'shifty', 'shine', 'shining', 'ship', 'shipley', 'shipman', 'shippensburg', 'shirtless', 'shit', 'shitewhat', 'shiver', 'shoal', 'shocker', 'shoot', 'shooter', 'shooting', 'shop', 'shopping', 'shore', 'shorncliffe', 'short', 'shortage', 'shortly', 'shot', 'shoulder', 'shouldnt', 'shoutout', 'shovel', 'showed', 'shower', 'showing', 'showlatest', 'shown', 'showyourcolors', 'shs', 'shtormstekcoma', 'shubertsomer', 'shumaria1', 'shut', 'shy', 'sick', 'sidewalk', 'sids', 'sight', 'sighted', 'sighting', 'sign', 'signage', 'signature', 'signed', 'significant', 'significantly', 'sigtor', 'silence', 'silent', 'silently', 'silly', 'similar', 'simple', 'simplest', 'simply', 'singer', 'single', 'siren', 'sirlinjohn', 'sirspitta', 'sister', 'sit', 'site', 'sits', 'sitting', 'situation', 'size', 'sj', 'sjwarsap', 'ska', 'skies', 'skill', 'skindont', 'skull', 'sky', 'skyskies', 'skywarn', 'skywarnky', 'slash', 'slave', 'slavery', 'sleep', 'sleeper', 'sleeping', 'sleeve', 'slept', 'slick', 'slidell', 'slight', 'slinging', 'slipped', 'slow', 'slumand', 'small', 'smelled', 'smilei', 'smiletrustinc', 'smite', 'smith', 'smoke', 'smoked', 'smothering', 'snacks', 'snag', 'snapped', 'snowstormhave', 'socalled', 'social', 'societyas', 'socioeconomic', 'sock', 'softball', 'soiled', 'soimagine', 'soky', 'sold', 'soldier', 'soleil', 'solely', 'soley', 'solidarity', 'solmightypirate', 'solo', 'solution', 'solved', 'solving', 'somethinglearn', 'sometimesi', 'somostbb', 'son', 'song', 'sonora', 'soon', 'sooner', 'sorta', 'souled', 'soulsome', 'sound', 'soundcloud', 'sounded', 'sounding', 'source', 'south', 'southeast', 'southeastern', 'southern', 'southwest', 'southwestern', 'sowal', 'soybean', 'space', 'spam', 'spann', 'spartanburg', 'spc', 'speaker', 'speaks', 'specialist', 'specie', 'specific', 'specifically', 'speech', 'speed', 'speeding', 'spencer', 'spend', 'spending', 'spent', 'spewing', 'spin', 'spinning', 'spinup', 'spitting', 'sploosh', 'spoiler', 'spoiling', 'spooky', 'sporadic', 'sporadically', 'sport', 'sportalabama', 'sportingkc', 'spot', 'spotr', 'spotsylvania', 'spotter', 'spout', 'spraberry', 'spreading', 'spring', 'springfield', 'springford', 'sprinkling', 'sprout', 'squabblingsomebody', 'squad', 'square', 'squaring', 'squigglyvolcano', 'sqweee', 'sse', 'ssw', 'st', 'stacey', 'staff', 'staffer', 'staffing', 'stage', 'stale', 'stalled', 'stand', 'standard', 'standing', 'stanley', 'stanleycup', 'stanleyville', 'star', 'staring', 'starkville', 'start', 'started', 'starting', 'starvation', 'starwarscelebration', 'state', 'statesville', 'station', 'stationary', 'statistically', 'stats', 'statue', 'status', 'stay', 'stayed', 'staying', 'steak', 'steakhouse', 'stealing', 'steel', 'step', 'steph', 'stephenking', 'sterling', 'stevebeylonwbay', 'stevebrusatte', 'stevencheah', 'steveschmidtses', 'stevesilcox', 'stick', 'sticky', 'stiffroboginger', 'stinky', 'stjoe', 'stl', 'stlblues', 'stock', 'stockholm', 'stocking', 'stone', 'stony', 'stop', 'stopped', 'stopschoolshootings', 'store', 'storm', 'stormchaseteam', 'stormchasing', 'stormdamage', 'stormhour', 'stormhuntertwn', 'stormi', 'stormreadyjoin', 'storms', 'stormso', 'stormwatch', 'stormy', 'story', 'stovepipe', 'straight', 'straightline', 'strangest', 'strategy', 'straw', 'streak', 'stream', 'streaming', 'streamlines', 'street', 'streets', 'strength', 'strengthens', 'stress', 'stricter', 'striding', 'strike', 'striking', 'stringer', 'strip', 'strmchsrhunterf', 'strong', 'stronger', 'strongest', 'struck', 'structure', 'struture', 'stucam1', 'stuck', 'student', 'study', 'studyingabroad', 'stuff', 'stupid', 'sturdy', 'styled', 'subject', 'subjecting', 'submerged', 'substantial', 'suburb', 'suburbanscanner', 'subway', 'sucked', 'sudden', 'suddenly', 'sue', 'suffered', 'suffers', 'sufficiently', 'suite', 'summer', 'summerst', 'summerton', 'summon', 'summoning', 'sun', 'sunburst', 'sunday', 'sunny', 'sunset', 'sunshine', 'super', 'supercell', 'supercells', 'supercellular', 'supercomputer', 'supply', 'support', 'supporting', 'suppose', 'supposed', 'supposedly', 'suprised', 'sure', 'surf', 'surge', 'surprise', 'surprised', 'surrounding', 'survey', 'surveyed', 'surveying', 'survive', 'suspect', 'suspected', 'suspicious', 'sussex', 'sustained', 'sutcliffe', 'svechnikov', 'svenskaflicka9', 'sw', 'swab', 'swamp', 'swapbc', 'swear', 'sweep', 'sweet', 'sweetie', 'swept', 'swipe', 'swrgov', 'symmes', 'szn', 't911', 't9911', 'tab', 'taceauxs', 'tackle', 'tackling', 'taco', 'tad', 'tadd', 'tag', 'tagging', 'tail', 'tailpipe', 'takeaway', 'takemeaway', 'taken', 'takin', 'taking', 'takotsubo', 'talk', 'talking', 'talkingpoint', 'tall', 'tampa', 'tap', 'taralanewx', 'target', 'tased', 'tasing', 'task', 'tasting', 'tattoo', 'taught', 'tax', 'taylorsville', 'tclife', 'tdwr', 'teach', 'teacher', 'teacherlife', 'teaching', 'team', 'teamrubiconsb', 'teamsissies', 'teapainusa', 'tear', 'tearing', 'technically', 'tectonic', 'tejay', 'tell', 'telling', 'temper', 'temperature', 'temple', 'temporary', 'tempt', 'tenacioustopper', 'tenacity', 'tend', 'tennis', 'tent', 'teravainen', 'term', 'terminal', 'terminalsbut', 'terpweather', 'terrible', 'terribly', 'terrified', 'terrifying', 'terrorism', 'terrorist', 'terrytown', 'tesla', 'test', 'tested', 'testimony', 'teuvo', 'texan', 'texas', 'texasoklahoma', 'texasschool', 'texasschoolmassacre', 'texaswelp', 'tf', 'tfox1', 'tgif', 'th', 'tha', 'thacarlfox1', 'thank', 'thankful', 'thankfully', 'thanks', 'thathurricaneis', 'thats', 'thatthe', 'theannaomaly', 'thebalorclubguy', 'thedjelliot', 'thedozentrivia', 'theerkj', 'thefinecats', 'theflood', 'thegoodgodabove', 'thejagmeetsingh', 'theleftbench', 'themattcast', 'theme', 'themnarrator', 'themplus', 'thenflchick', 'thenikkirosa', 'thentoday', 'thephotohour', 'therealmccoy1', 'therobdale', 'thetribute', 'theyd', 'theyll', 'theyre', 'theyve', 'thighlandbunny', 'thing', 'think', 'thinking', 'thinly', 'thirty', 'thirtyfive', 'thiswe', 'tho', 'thomas', 'thomasville', 'thon', 'thoseterribletwisters', 'thought', 'thoughtsandprayers', 'thousand', 'thread', 'threat', 'threeonepour', 'threesome', 'thrive', 'throat', 'throne', 'throughoutsee', 'throw', 'throwbackthursday', 'throwing', 'thrown', 'thscattered', 'thu', 'thunder', 'thunderstorm', 'thursday', 'ticket', 'tickpick', 'tide', 'tied', 'tiktok', 'til', 'tilghman', 'tilghmanbottom', 'till', 'timberlake', 'timblor', 'time', 'timelapse', 'timeline', 'timemust', 'timenwstallahassee', 'timeof', 'timer', 'timing', 'timlammersfox1', 'timodc', 'tin', 'tint', 'tiny', 'tip', 'tippacanoe', 'tippecanoe', 'tipped', 'tire', 'tired', 'tirz', 'titan', 'titicaca', 'title', 'tl', 'tlongthepeople', 'tn', 'tngop', 'tobaccoville', 'today', 'todayand', 'todaymain', 'todd', 'toddler', 'toes', 'toget', 'toilet', 'tokyo', 'told', 'toll', 'tom', 'tomcottonar', 'tomdutty', 'tomilahren', 'tommy', 'tommys', 'tomorrow', 'tomwentworth', 'ton', 'tonesdrop', 'tonga', 'tongue', 'tonight', 'tony', 'toobusywinning', 'took', 'tool', 'toolubbocks', 'tooo', 'topped', 'topranked', 'tor', 'tore', 'torgttornado', 'tornada', 'tornade', 'tornadic', 'tornado', 'tornadoalley', 'tornadoes', 'tornadohey', 'tornadohurricane', 'tornadohydrogen', 'tornadoofroses', 'tornadosteejo', 'tornadoswarnings', 'tornadowarned', 'tornadowarning', 'tornadowatch', 'tornadowe', 'torontofire', 'torrential', 'tossing', 'total', 'totality', 'totally', 'toto', 'touch', 'touchdown', 'touched', 'touching', 'tough', 'tour', 'tourney', 'towel', 'tower', 'towery', 'town', 'toxic', 'tpffa', 'track', 'tracked', 'tracking', 'tractor', 'tracy', 'tracymorningst1', 'trade', 'tradition', 'traffic', 'tragedy', 'tragic', 'tragically', 'trail', 'trailer', 'train', 'trained', 'training', 'transformation', 'transition', 'trap', 'trapped', 'trauma', 'traumatic', 'travel', 'traveling', 'travisbranham', 'tree', 'treesthats', 'tremor', 'trend', 'trentlyons', 'triad', 'trial', 'trick', 'trickle', 'tried', 'trifecta', 'trigger', 'trip', 'trippinapenft', 'tristansnell', 'tristate', 'trocchiophoto', 'trocheck', 'troll', 'tropethen', 'tropical', 'tropics', 'trotwood', 'troutinplaid', 'troy', 'truck', 'true', 'truegrit', 'truly', 'trump', 'trust', 'trusted', 'truth', 'truthtornado', 'trvcepilotss', 'try', 'trying', 'tryna', 'tstm', 'tstorms', 'tsunami', 'tucker', 'tues', 'tuesday', 'tuned', 'tunnel', 'turkey', 'turkish', 'turn', 'turnarounddontdrown', 'turned', 'turning', 'turnout', 'turnttrav', 'tuscaloosa', 'tutorial', 'tv', 'tvnewsmemories', 'tweeps', 'tweet', 'tweeting', 'twice', 'twister', 'twitter', 'twittersupport', 'tx', 'txwx', 'type', 'typeusage', 'typhoon', 'typical', 'typocat', 'ubiquitous', 'ucf', 'uga', 'ugh', 'ugly', 'ukraine', 'ultrasound', 'umbrella', 'unable', 'unarmed', 'unbeatable', 'uncounted', 'underexposed', 'underrated', 'understand', 'understanding', 'understandunfortunately', 'underway', 'unhinged', 'unhingedcustoms', 'uniform', 'union', 'unique', 'unit', 'united', 'unitedway', 'university', 'unknown', 'unleash', 'unless', 'unlike', 'unreal', 'unsafe', 'unsignedartist', 'unstable', 'unthinkable', 'unwilling', 'upcoming', 'upda', 'update', 'updatecomplete', 'updatenick', 'upgrade', 'upgraded', 'uprooted', 'uprooting', 'ups', 'upside', 'upstate', 'urgent', 'usa', 'usc', 'use', 'used', 'user', 'usfnolans', 'usgs', 'usgs19', 'usgsvolcanoes', 'usi', 'using', 'usoc', 'usps', 'usual', 'usually', 'usyour', 'utah', 'utc', 'uvalde', 'uvaldeelementary', 'uvaldemassacre', 'uvaldeschoolmassacre', 'uvaldestrong', 'uvaldetexas', 'uvelde', 'uw', 'uxbridge', 'va', 'va9', 'vagina', 'valley', 'van', 'vance', 'vanish', 'varedcross', 'various', 'vawx', 'vdot', 'veecon', 'veedersburg', 'vehicle', 'vehiclerelated', 'vei', 'veiled', 'velocity', 'venice', 'venmo', 'ventricle', 'verdad', 'vermillion', 'verndale', 'version', 'verts', 'veterans', 'vibe', 'vicinity', 'vicious', 'victor', 'victory', 'video', 'vienna', 'view', 'viewer', 'viewing', 'villa', 'village', 'vincent', 'violence', 'violencei', 'violent', 'violette', 'viral', 'virgin', 'virginia', 'virginiauntil', 'virtual', 'visible', 'vision', 'visit', 'visiting', 'visualization', 'vlads', 'vmaun', 'vodka', 'voice', 'volcano', 'volcanology', 'volume', 'volunteer', 'vortex', 'vote', 'votebluetosaveamerica', 'voteontario', 'voting', 'vr', 'vu', 'vulnerable', 'vwhere', 'wa', 'wadena', 'wadesboro', 'wading', 'waffle', 'waiste', 'wait', 'waited', 'waiting', 'waiya', 'waiyayall', 'wake', 'walk', 'walker', 'walking', 'wall', 'wallace', 'walleyeguy11', 'wallpaper', 'walshfreedom', 'waltdisneyworld', 'walton', 'wan', 'wandering', 'wanna', 'want', 'wanted', 'wanting', 'war', 'warcholalieutenantfire', 'ware', 'warehouse', 'warm', 'warned', 'warning', 'warningbut', 'warningnot', 'warningraindark', 'warnings', 'warningyou', 'warnocks', 'warring', 'warrior', 'wash', 'washed', 'washer', 'washing', 'washington', 'wasnt', 'watch', 'watched', 'watching', 'water', 'waterdamage', 'waterloo', 'watershed', 'waterspout', 'wave', 'wavy1bob', 'wavynews', 'wavyrickym', 'wax', 'way', 'waynetown', 'wbffamy', 'wbi', 'wbrcfirstalert', 'wckitchen', 'wcredit', 'wdbj', 'wdbjleohirsbrunner', 'weaforecasting', 'weak', 'weakened', 'weakening', 'weaker', 'weallbleedblue', 'wealthy', 'wealthyand', 'weapon', 'wear', 'wearing', 'weary', 'weather', 'weatherab', 'weatheraware', 'weatherchannel', 'weathered', 'weatherman', 'weathernation', 'weathernetwork', 'weathernews', 'weatherready', 'webelievejohnnydepp', 'webster', 'wed', 'wedge', 'wednesday', 'week', 'weekandahalf', 'weekdont', 'weekend', 'weekweekend', 'weenie', 'wef', 'wegotthis', 'weird', 'wellington', 'welp', 'wendell', 'went', 'werent', 'werewolf', 'west', 'westby', 'western', 'westernuntp', 'westlake', 'westmanland', 'westminstermd', 'weve', 'wfos', 'wfunds', 'wfxrnews', 'whacky', 'whale', 'whats', 'whatthey', 'wheaton', 'wheel', 'wheeling', 'whim', 'white', 'whiteface', 'whitefacetx', 'whitesnake', 'whiteweather', 'whodamoney1', 'whore', 'whow', 'whsvnews', 'wi', 'wichita', 'wide', 'widespread', 'width', 'wife', 'wild', 'wildfire', 'wilkes', 'wilkesboro', 'wilkin', 'willardpenny', 'willc', 'win', 'winchester', 'wind', 'window', 'windsonly', 'windswr', 'wine', 'winfield', 'wing', 'wingate', 'winnebago', 'winner', 'winstonsalem', 'winterset', 'wires', 'wisbbyearbook', 'wisconsin', 'wish', 'wishing', 'wit', 'witnessed', 'wiwx', 'wjhgtv', 'wltx', 'wmiwx', 'wmsb', 'wnba', 'wncwx', 'wnd', 'wnw', 'wofs', 'wolverton', 'woman', 'won', 'wonder', 'wondered', 'wonderful', 'wont', 'wood', 'wooden', 'woodtvcom', 'word', 'wording', 'wordsofdomingo', 'work', 'workable', 'worked', 'worker', 'working', 'workit', 'workout', 'workplace', 'workshop', 'workssorry', 'workyourland', 'world', 'worldhistory', 'worried', 'worry', 'worse', 'worsening', 'worshipped', 'worst', 'worth', 'wouldnt', 'wow', 'wowall', 'wrapped', 'wrestling', 'write', 'writing', 'writingcommunity', 'wrong', 'wrote', 'wset', 'wsls', 'wslsmichaels', 'wsoc', 'wsw', 'wtf', 'wthark', 'wthe', 'wtkr', 'wtvaweather', 'wusa9', 'wv', 'wx', 'wxatlantic', 'wxbrad', 'wxman', 'wxreport', 'wxtwitter', 'wxzachary', 'wya', 'wylie', 'wyndham', 'wyoming', 'xarbage', 'xoxo', 'xpumpkinspice', 'ya', 'yaaay', 'yadkin', 'yagocerqueirat1', 'yah', 'yall', 'yalls', 'yankee', 'yard', 'yass', 'yates', 'yay', 'yea', 'yeah', 'year', 'yearly', 'yearoverbooked', 'yearsin', 'yeddo', 'yeet', 'yellow', 'yes', 'yesterday', 'yesterdaywusa9', 'yknow', 'ymca', 'yo', 'yoga', 'york', 'yorkage', 'yorknew', 'youll', 'young', 'youngster', 'youre', 'youth', 'youtube', 'youve', 'yr', 'yrds', 'yung', 'yup', 'zama', 'zamboni', 'zentmyer', 'zephyr', 'zero', 'zevon', 'zig', 'zinks', 'zoikes', 'zone']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "twitter_w_cloud = count_vect.get_feature_names()\n",
    "\n",
    "print(twitter_w_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97d733ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tornado       1144\n",
       "warning        487\n",
       "pm             416\n",
       "flood          392\n",
       "edt            355\n",
       "nc             258\n",
       "report         251\n",
       "wa             202\n",
       "including      178\n",
       "cdt            151\n",
       "va             150\n",
       "storm          143\n",
       "continues      137\n",
       "county         133\n",
       "watch          118\n",
       "drill          108\n",
       "flash          106\n",
       "just            93\n",
       "amp             91\n",
       "near            84\n",
       "hurricane       77\n",
       "like            73\n",
       "day             66\n",
       "ha              66\n",
       "earthquake      66\n",
       "weather         64\n",
       "delayed         64\n",
       "nw              63\n",
       "im              60\n",
       "road            55\n",
       "sc              54\n",
       "time            53\n",
       "school          52\n",
       "wind            52\n",
       "survey          52\n",
       "ky              51\n",
       "today           51\n",
       "flooding        51\n",
       "water           48\n",
       "tx              46\n",
       "north           44\n",
       "dont            44\n",
       "need            44\n",
       "public          43\n",
       "ia              43\n",
       "west            42\n",
       "gun             42\n",
       "il              41\n",
       "area            41\n",
       "11              40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100 = pd.DataFrame(twitter_words_d, columns= count_vect.get_feature_names())\n",
    "\n",
    "twitter_words = top_100.sum().sort_values(ascending=False).head(50)\n",
    "\n",
    "twitter_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f61f18b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'sort_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     plt\u001b[38;5;241m.\u001b[39myticks(size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m)\n\u001b[1;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(title, size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m);\n\u001b[0;32m---> 10\u001b[0m \u001b[43mbar_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtwitter_words_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMost Common Words in Non-Urgent Tweets\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36mbar_graph\u001b[0;34m(df, title)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbar_graph\u001b[39m(df, title):\n\u001b[1;32m      3\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m----> 4\u001b[0m     (\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10\u001b[39m])\u001b[38;5;241m.\u001b[39mplot(kind \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbarh\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcornflowerblue\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m     plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrequency\u001b[39m\u001b[38;5;124m'\u001b[39m, size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m)\n\u001b[1;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWords\u001b[39m\u001b[38;5;124m'\u001b[39m, size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'sort_values'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of most frequent words for the natural disaster\n",
    "def bar_graph(df, title):\n",
    "    plt.figure(figsize = (8, 8))\n",
    "    (df.sum().sort_values(ascending=False)[0:10]).plot(kind = 'barh', color='cornflowerblue')\n",
    "    plt.xlabel('Frequency', size = 15)\n",
    "    plt.ylabel('Words', size = 15)\n",
    "    plt.yticks(size = 15)\n",
    "    plt.title(title, size = 15);\n",
    "\n",
    "bar_graph(twitter_words_d, 'Most Common Words in Non-Urgent Tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7f3319",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816718ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bf9b73c",
   "metadata": {},
   "source": [
    "We're going to create a custom list of stop words so we can remove some of the words that were showing up in both of our positive and negative classes. These include the words that were originally used to scrape the posts from Twitter, so obviously they would be in every one of our posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9957d20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['everything', 'something', 'whoever', 'she', 'someone', 'interest', 'up', 'even', 'thereupon', 'should', 'yet', 'without', 'fifty', 'if', 'were', 'when', 'front', 'per', 'hundred', 'thick', 'became', 'below', 'anyway', 're', 'could', 'a', 'their', 'fill', 'less', 'eleven', 'off', 'fire', 'among', 'then', 'before', 'whom', 'since', 'himself', 'so', 'mostly', 'well', 'again', 'hence', 'sometime', 'whereas', 'back', 'cannot', 'every', 'con', 'everywhere', 'least', 'seems', 'take', 'go', 'call', 'five', 'was', 'found', 'co', 'is', 'name', 'while', 'nevertheless', 'wherever', 'between', 'though', 'towards', 'hers', 'get', 'very', 'yours', 'already', 'we', 'herein', 'whereafter', 'may', 'hereby', 'they', 'will', 'side', 'seemed', 'than', 'because', 'much', 'formerly', 'these', 'ie', 'anywhere', 'us', 'besides', 'made', 'top', 'too', 'amoungst', 'been', 'any', 'i', 'over', 'how', 'where', 'move', 'being', 'many', 'amount', 'eg', 'also', 'beyond', 'whole', 'elsewhere', 'done', 'own', 'whither', 'twenty', 'what', 'fifteen', 'am', 'why', 'latter', 'inc', 'other', 'moreover', 'until', 'neither', 'hasnt', 'throughout', 'but', 'everyone', 'next', 'must', 'onto', 'hereafter', 'detail', 'here', 'give', 'from', 'within', 'sometimes', 'sincere', 'anything', 'at', 'still', 'our', 'therefore', 'those', 'the', 'indeed', 'empty', 'with', 'etc', 'his', 'wherein', 'please', 'see', 'there', 'namely', 'few', 'whenever', 'otherwise', 'six', 'else', 'whence', 'has', 'once', 'on', 'ourselves', 'noone', 'nothing', 'he', 'yourselves', 'nowhere', 'none', 'part', 'couldnt', 'another', 'therein', 'two', 'down', 'yourself', 'first', 'along', 'nor', 'upon', 'describe', 'never', 'alone', 'and', 'or', 'would', 'your', 'itself', 'thence', 'ever', 'of', 'somewhere', 'them', 'an', 'seeming', 'further', 'me', 'that', 'ltd', 'you', 'several', 'always', 'not', 'its', 'as', 'this', 'whose', 'whether', 'have', 'against', 'only', 'no', 'system', 'her', 'toward', 'thereafter', 'whereby', 'become', 'which', 'perhaps', 'others', 'due', 'keep', 'four', 'except', 'him', 'thin', 'after', 'now', 'ten', 'under', 'are', 'one', 'thru', 'former', 'each', 'although', 'enough', 'can', 'eight', 'anyhow', 'put', 'ours', 'either', 'seem', 'mill', 'rather', 'behind', 'around', 'becoming', 'themselves', 'amongst', 'serious', 'might', 'through', 'together', 'un', 'cry', 'becomes', 'somehow', 'bottom', 'most', 'thus', 'beside', 'who', 'almost', 'third', 'across', 'three', 'however', 'in', 'bill', 'myself', 'sixty', 'last', 'show', 'meanwhile', 'for', 'into', 'hereupon', 'above', 'thereby', 'to', 'cant', 'mine', 'during', 'do', 'forty', 'latterly', 'whereupon', 'by', 'de', 'afterwards', 'both', 'herself', 'full', 'all', 'more', 'beforehand', 'nine', 'nobody', 'find', 'twelve', 'via', 'anyone', 'whatever', 'out', 'it', 'my', 'had', 'about', 'same', 'often', 'some', 'be', 'such']\n"
     ]
    }
   ],
   "source": [
    "stop_words = list(_stop_words.ENGLISH_STOP_WORDS)\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a9da6",
   "metadata": {},
   "source": [
    "### Set up our data for modeling\n",
    "- `X` will be the `content` column.\n",
    "- `y` will be the `target` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfdebcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2728d953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61677a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ad4483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e998d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df[\"content\"]\n",
    "y= df[\"target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "901321b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.577872\n",
       "1    0.422128\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63f7ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f6f1b",
   "metadata": {},
   "source": [
    "### Model_1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1443d1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set it up with two stages:\n",
    "# 1. An instance of CountVectorizer (transformer)\n",
    "# 2. A LogisticRegression instance (estimator)\n",
    "\n",
    "pipe= Pipeline([('cvec',CountVectorizer()),\n",
    "\n",
    "                ('lr', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5594f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {'cvec__max_features': [1000,4000,6000],\n",
    "              'cvec__min_df' :[2,3],\n",
    "               'cvec__max_df' :[0.95,0.98],\n",
    "               'cvec__ngram_range' :[(1,1),(1,2),(1,3)]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "869496fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs = GridSearchCV(pipe, # what object are we optimizing?\n",
    "                  param_grid = pipe_params, # what parameters values are we searching?\n",
    "                  cv=5) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "962dd014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             param_grid={'cvec__max_df': [0.95, 0.98],\n",
       "                         'cvec__max_features': [1000, 4000, 6000],\n",
       "                         'cvec__min_df': [2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)]})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to training data.\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ada4f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9745207792613902"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the best score?\n",
    "gs.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efc40a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 CountVectorizer(max_df=0.95, max_features=6000, min_df=2,\n",
       "                                 ngram_range=(1, 3))),\n",
       "                ('lr', LogisticRegression())])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save best model as gs_model.\n",
    "#Pipeline(steps=[('cvec',\n",
    "                # CountVectorizer(max_df=0.95, max_features=4000, min_df=2)),\n",
    "                #('lr', LogisticRegression())])\n",
    "gs_model = gs.best_estimator_\n",
    "gs_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d2eb0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9978768577494692\n",
      "0.9734888653234358\n"
     ]
    }
   ],
   "source": [
    "# Score model on training set.\n",
    "print(gs_model.score(X_train, y_train))\n",
    "\n",
    "# Score model on testing set.\n",
    "print(gs_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e99546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_CV = gs_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03dd2287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 535\n",
      "False Positives: 10\n",
      "False Negatives: 15\n",
      "True Positives: 383\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_CV).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42ccfdc",
   "metadata": {},
   "source": [
    "### Model_2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "173f911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_1= Pipeline([('tvec', TfidfVectorizer()),\n",
    "\n",
    "                ('lr', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a0441d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit: 1000, 4000, 6000\n",
    "# Minimum number of documents needed to include token: 2, 3\n",
    "# Maximum number of documents needed to include token: 95%, 98%\n",
    "# Check (individual tokens) and also check (individual tokens and bigrams).\n",
    "\n",
    "\n",
    "pipe_params_1= {\n",
    "            'tvec__stop_words' : [None, 'english'],\n",
    "            'tvec__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "            'tvec__max_df' : [.95, 0.98],\n",
    "            'tvec__min_df' : [2, 3],\n",
    "            'tvec__max_features' : [1000, 4000, 6000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "920681c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_1= GridSearchCV(pipe_1, # what object are we optimizing?\n",
    "                  param_grid =pipe_params_1 , # what parameters values are we searching?\n",
    "                  cv=5, n_jobs=-1, verbose=1) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9867eda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                       ('lr', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'tvec__max_df': [0.95, 0.98],\n",
       "                         'tvec__max_features': [1000, 4000, 6000],\n",
       "                         'tvec__min_df': [2, 3],\n",
       "                         'tvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'tvec__stop_words': [None, 'english']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7989da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525820069420557"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the best score?\n",
    "gs_1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbb29c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tvec',\n",
       "                 TfidfVectorizer(max_df=0.95, max_features=1000, min_df=2,\n",
       "                                 ngram_range=(1, 3), stop_words='english')),\n",
       "                ('lr', LogisticRegression())])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save best model as gs_model.\n",
    "#Pipeline(steps=[('tvec',\n",
    "                # TfidfVectorizer(max_df=0.95, max_features=4000, min_df=2)),\n",
    "                #('lr', LogisticRegression())])\n",
    "gs_model_1 = gs_1.best_estimator_\n",
    "gs_model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb96682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9766454352441614\n",
      "0.9490986214209968\n"
     ]
    }
   ],
   "source": [
    "# Score model on training set.\n",
    "print(gs_model_1.score(X_train, y_train))\n",
    "\n",
    "# Score model on testing set.\n",
    "print(gs_model_1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62cf0836",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_1 = gs_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e924c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 535\n",
      "False Positives: 10\n",
      "False Negatives: 15\n",
      "True Positives: 383\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions_1).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038beb75",
   "metadata": {},
   "source": [
    "### Model_3: BernoulliNB , MultinomialNB, GaussianNV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdcd55d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate our CountVectorizer.\n",
    "cvec_1 = CountVectorizer(max_features=4000, stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c23aa345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our CountVectorizer on the training data and transform training data.\n",
    "X_train_cvec =cvec_1.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a8a95d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform our testing data with the already-fit CountVectorizer.\n",
    "X_test_cvec = cvec_1.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0938d7",
   "metadata": {},
   "source": [
    "### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cbf110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our model!\n",
    "\n",
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25c612ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit our model!\n",
    "\n",
    "bnb.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a7d5912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9345339128803278"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score=cross_val_score(bnb, X_train_cvec, y_train, cv=5).mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e4721ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our predictions!\n",
    "\n",
    "predictions = bnb.predict(X_test_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77e20833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9289501590668081\n",
      "0.9564755838641189\n"
     ]
    }
   ],
   "source": [
    "# Score our model on the training set.\n",
    "\n",
    "print(bnb.score(X_test_cvec, y_test))\n",
    "\n",
    "# Score our model on the testing set.\n",
    "print(bnb.score(X_train_cvec, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa23a5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 488\n",
      "False Positives: 57\n",
      "False Negatives: 10\n",
      "True Positives: 388\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6004b947",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d85115e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9610757254069356\n",
      "0.9247083775185578\n"
     ]
    }
   ],
   "source": [
    "# Similarly Multinomial NB\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "mnb.fit(X_train_cvec, y_train)\n",
    "\n",
    "pred_multinomial = mnb.predict(X_test_cvec)\n",
    "\n",
    "print(mnb.score(X_train_cvec, y_train))\n",
    "\n",
    "print(mnb.score(X_test_cvec, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8a4c18a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9306426092122955"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score=cross_val_score(mnb, X_train_cvec, y_train, cv=5).mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c13b4310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 482\n",
      "Fale Positives: 63\n",
      "False Negatives: 8\n",
      "True Positives: 390\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, pred_multinomial).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"Fale Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4643a7a5",
   "metadata": {},
   "source": [
    "### GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35dd3726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9989384288747346\n",
      "0.9353128313891834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train_cvec.todense(), y_train)\n",
    "\n",
    "pred_gnb = gnb.predict(X_test_cvec.todense())\n",
    "\n",
    "print(gnb.score(X_train_cvec.todense(), y_train))\n",
    "\n",
    "print(gnb.score(X_test_cvec.todense(), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "641a759d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9239200725476093"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score=cross_val_score(gnb, X_train_cvec.todense(), y_train, cv=5).mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ced8d1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 501\n",
      "Fale Positives: 44\n",
      "False Negatives: 17\n",
      "True Positives: 381\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, pred_gnb).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"Fale Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83b6fab",
   "metadata": {},
   "source": [
    "## RandomForest - Model  4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5efb9f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Instantiation\n",
    "# Create an instance of RandomForestClassifier and ExtraTreesClassifier.\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "et = ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d14a15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9628423928025462"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Evaluation for rf and et\n",
    "cross_val_score(rf,X_train_cvec,y_train, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c92987e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9582399819562439"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Evaluation for rf and et\n",
    "cross_val_score(et,X_train_cvec,y_train, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8fffa28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [50,75,100,500],\n",
    "    'max_depth': [10,15,20,30],\n",
    "    'min_samples_split': [2,5,10],\n",
    "    'min_samples_leaf':[1,3,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fff748ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': [10, 15, 20, 30],\n",
       "                         'min_samples_leaf': [1, 3, 5],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [50, 75, 100, 500]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearch\n",
    "\n",
    "gs3= GridSearchCV(estimator = RandomForestClassifier(random_state = 42),param_grid=rf_params, cv=10, verbose=1, n_jobs=-1)\n",
    "\n",
    "gs3.fit(X_train_cvec,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "604fa925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936300528782297"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Score\n",
    "\n",
    "gs3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d85878bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Parameters\n",
    "gs3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7331d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning to best_estimators\n",
    "best_rf = gs3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "65aa8664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=30, min_samples_split=10, n_estimators=500,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit train data\n",
    "best_rf.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e58a93e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9483368719037509\n",
      "0.9183457051961824\n"
     ]
    }
   ],
   "source": [
    "# Score\n",
    "print(best_rf.score(X_train_cvec, y_train))\n",
    "\n",
    "# Test Score\n",
    "print(best_rf.score(X_test_cvec, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3af88b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pred_rf = best_rf.predict(X_test_cvec.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db66ddd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 475\n",
      "False Positives: 70\n",
      "False Negatives: 7\n",
      "True Positives: 391\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, pred_rf).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385de16f",
   "metadata": {},
   "source": [
    "### Support Vector Machine - Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2bf5852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate support vector machine.\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be801583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit support vector machine to training data.\n",
    "svc.fit(X_train_cvec, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e84611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions.\n",
    "\n",
    "y_pred = svc.predict(X_test_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7ee388da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9922151450813871"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Measure performance based on accuracy.\n",
    "svc.score(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8aba086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9639448568398727"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mesure of test score\n",
    "svc.score(X_test_cvec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "04201259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     predicted  actual\n",
       "0            0     NaN\n",
       "1            1     0.0\n",
       "2            1     NaN\n",
       "3            0     NaN\n",
       "4            1     0.0\n",
       "..         ...     ...\n",
       "938          0     0.0\n",
       "939          0     NaN\n",
       "940          0     NaN\n",
       "941          0     NaN\n",
       "942          0     NaN\n",
       "\n",
       "[943 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame with column for predicted values.\n",
    "results = pd.DataFrame(svc.predict(X_test_cvec), columns=['predicted'])\n",
    "\n",
    "# Create column for observed values.\n",
    "results['actual'] = y_test\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f05e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = {\n",
    "    'kernel':['linear','rbf','polynomial']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "70196cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Applications/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"/Applications/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 342, in _sparse_fit\n",
      "    kernel_type = self._sparse_kernels.index(kernel)\n",
      "ValueError: 'polynomial' is not in list\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.96709145 0.96355287        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(random_state=42), n_jobs=-1,\n",
       "             param_grid={'kernel': ['linear', 'rbf', 'polynomial']}, verbose=1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs5= GridSearchCV(estimator = SVC(random_state = 42),param_grid=svm_params, cv=10, verbose=1, n_jobs=-1)\n",
    "\n",
    "gs5.fit(X_train_cvec,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4e054904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9670914467583891"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Score\n",
    "\n",
    "gs5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9307b9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'linear'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Parameters\n",
    "gs5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "287cafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning to best_estimators\n",
    "best_svm = gs5.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e249e226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit train data\n",
    "\n",
    "best_svm.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e4ddae4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996461429582448"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score\n",
    "best_svm.score(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "620fa7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9671261930010604"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test Score\n",
    "best_svm.score(X_test_cvec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4d889fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pred_svm = best_svm.predict(X_test_cvec.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c6667a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 537\n",
      "False Positives: 8\n",
      "False Negatives: 23\n",
      "True Positives: 375\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, pred_svm).ravel()\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc3281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f026c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33044fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5d4531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
